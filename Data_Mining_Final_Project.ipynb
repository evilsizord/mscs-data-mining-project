{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNX30PkgX/GSpUV+LTlHOGU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/evilsizord/mscs-data-mining-project/blob/main/Data_Mining_Final_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Product Review Classification\n",
        "Final Project \\\n",
        "CSE 5334 - Data Mining \\\n",
        "Daniel Evilsizor \\\n",
        "November 13, 2022"
      ],
      "metadata": {
        "id": "XQM0pRlgfLq9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get Data from Kaggle.com\n",
        "\n",
        "# NOTE: Requires you to have a Kaggle.com account. From your account you can generate an API key.\n",
        "# It will be provided in kaggle.json. Upload the JSON file to this project BEFORE RUNNING.\n",
        "\n",
        "# src: https://www.kaggle.com/general/74235\n",
        "\n",
        "! pip install -q kaggle\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle datasets download vivekgediya/ecommerce-product-review-data\n",
        "! mkdir dataset\n",
        "! unzip ecommerce-product-review-data.zip -d dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhmeJ5GQfVE3",
        "outputId": "067a8f88-2383-4b98-b39d-aaad7b03950b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading ecommerce-product-review-data.zip to /content\n",
            "\r  0% 0.00/8.55M [00:00<?, ?B/s]\r 94% 8.00M/8.55M [00:00<00:00, 82.6MB/s]\n",
            "\r100% 8.55M/8.55M [00:00<00:00, 86.7MB/s]\n",
            "Archive:  ecommerce-product-review-data.zip\n",
            "  inflating: dataset/Automotive_5.json  \n",
            "  inflating: dataset/Flipkart_Reviews - Electronics.csv  \n",
            "  inflating: dataset/Product Review Data.csv  \n",
            "  inflating: dataset/Product Review Large Data.csv  \n",
            "  inflating: dataset/electronics_reviews_uniq.json  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load all necessary libraries\n",
        "import os\n",
        "from collections import defaultdict\n",
        "import pandas\n",
        "import nltk\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import datasets, layers, models, losses\n",
        "from sklearn import tree\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.metrics import confusion_matrix, classification_report,precision_recall_fscore_support\n",
        "from sklearn.model_selection import cross_val_score, cross_val_predict, train_test_split\n",
        "\n",
        "nltk.download('punkt')  # needed for tokenizer\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ia4MspXxfWl7",
        "outputId": "a6e772ad-f50d-4ae6-ad11-230d1066e670"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyTokenizer:\n",
        "  def __init__(self):\n",
        "    self.stemmer = SnowballStemmer(\"english\")\n",
        "    self.stop_words = set(stopwords.words('english'))\n",
        "\n",
        "  def tokenize(self, doc):\n",
        "    # strip punctuation, it's not needed\n",
        "    # ref: https://stackoverflow.com/questions/3411771/best-way-to-replace-multiple-characters-in-a-string\n",
        "    chars = \"/*[]()>#+,.!;:?\"\n",
        "    for c in chars:\n",
        "        doc = doc.replace(c, \" \")\n",
        "    tokens = word_tokenize(doc)\n",
        "    # remove stop words\n",
        "    # ref: https://stackoverflow.com/questions/15547409/how-to-get-rid-of-punctuation-using-nltk-tokenizer\n",
        "    # Also, convert to a set so we only get unique words per row (no duplicates)\n",
        "    words = set()\n",
        "    for tok in tokens:\n",
        "      word = self.stemmer.stem(tok)\n",
        "      if not word.lower() in self.stop_words:\n",
        "        words.add(word)\n",
        "    return words\n",
        "\n",
        "\n",
        "class NaiveBayesClassifier:\n",
        "\n",
        "  def __init__(self, vocab, classes, tokenizer):\n",
        "    self.class_counts = self.new_default_zero_dict()\n",
        "    self.class_probs = self.new_default_zero_dict()     # p(class)\n",
        "    self.classes = classes                              # [class1, class2, ..]\n",
        "    self.word_probs = self.new_default_zero_dict()      # p(w|class)\n",
        "    #self.post_probs = {}      # p(class|w)\n",
        "    self.word_counts = self.new_default_zero_dict()     # {total:n1, class1: n2, ... }\n",
        "    self.tokenizer = tokenizer\n",
        "    self.use_smoothing = False\n",
        "\n",
        "    for word in vocab:\n",
        "      self.word_counts[word] = self.new_default_zero_dict()\n",
        "\n",
        "  def __default_zero__():\n",
        "    return 0\n",
        "  \n",
        "  def new_default_zero_dict(self):\n",
        "    return defaultdict(lambda: 0)\n",
        "\n",
        "  def count_frequencies(self, dataset):\n",
        "    for row in dataset:\n",
        "      words = self.tokenizer.tokenize(row['sentence'])\n",
        "      y = row['class']\n",
        "      self.class_counts[y] += 1\n",
        "\n",
        "      # count overall word frequency, and frequency per class (label)\n",
        "      for word in words:\n",
        "        self.word_counts[word]['total'] += 1\n",
        "        self.word_counts[word][y] += 1\n",
        "\n",
        "    for c in self.classes:\n",
        "      self.class_probs[c] = self.class_counts[c] / len(dataset)\n",
        "\n",
        "  # calculate probs from a training dataset\n",
        "  def train(self, dataset):\n",
        "    self.count_frequencies(dataset)\n",
        "\n",
        "    # Calculate\tConditional probability of all words based on category\n",
        "    num_words = len(self.word_counts)\n",
        "    for word in self.word_counts:\n",
        "      for c in self.classes:\n",
        "        #\tP(word|class)  = # of documents in category containing word / num of all documents in that category\n",
        "        word_cat_freq = self.word_counts[word][c]\n",
        "        key = word + '__' + str(c)\n",
        "        if self.use_smoothing:\n",
        "          self.word_probs[key] = (word_cat_freq + 1) / (self.class_counts[c] + num_words)\n",
        "        else:\n",
        "          self.word_probs[key] = word_cat_freq / self.class_counts[c]\n",
        "\n",
        "  # return most likely class for each document\n",
        "  def predict(self, dataset):\n",
        "    # foreach document:\n",
        "    #  foreach class, calculate p(class|tokens) = p(tokens|class)*p(class) / p(tokens)\n",
        "    # (since p(tokens) is effectively a constant scaling factor when comparing these, we can ignore it)\n",
        "    Y_hat = []\n",
        "    for row in dataset:\n",
        "      words = self.tokenizer.tokenize(row['sentence'])\n",
        "      probs = {}\n",
        "      for c in self.classes:\n",
        "        p = self.class_probs[c]\n",
        "        for w in words:\n",
        "          p *= self.word_probs[(w + '__' + str(c))]\n",
        "        probs[c] = p\n",
        "      \n",
        "      # predicted class is the one with max probability\n",
        "      Y_hat.append(max(probs, key=probs.get))\n",
        "      \n",
        "    return Y_hat\n",
        "\n",
        "  def get_predictors(self, arg_class, vocab_probs):\n",
        "    predictors = {}\n",
        "    for word in self.word_counts:\n",
        "      # p(class|word) = p(word|class)*p(class)/p(word)\n",
        "      if word in vocab_probs:\n",
        "        predictors[word] = self.word_probs[word + '__' + str(arg_class)] * self.class_probs[arg_class] / vocab_probs[word]\n",
        "      else:\n",
        "        predictors[word] = 0\n",
        "    return predictors\n",
        "\n"
      ],
      "metadata": {
        "id": "HX5XWxBB0zCe"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "infile1 = pandas.read_json('dataset/Automotive_5.json', lines=True)\n",
        "infile2 = pandas.read_json('dataset/electronics_reviews_uniq.json', orient='records')\n",
        "infile3 = pandas.read_csv('dataset/Flipkart_Reviews - Electronics.csv')\n",
        "\n",
        "# Standardize column headings to: (class, review, review_title)\n",
        "infile1.rename(columns={'overall': 'class', 'reviewText': 'review', 'summary': 'review_title'}, inplace=True)\n",
        "infile2.rename(columns={'description': 'review', 'rating': 'class'}, inplace=True)\n",
        "infile3.rename(columns={'summary': 'review_title', 'rating': 'class'}, inplace=True)\n",
        "\n",
        "def format_data(df):\n",
        "  # convert all rating values to ints (1-5)\n",
        "  # todo: check for any invalid rating values\n",
        "  df = df.astype({\"class\": int})\n",
        "\n",
        "  # Combine the review with the summary (review title)\n",
        "  # ref: https://sparkbyexamples.com/pandas/pandas-combine-two-columns-of-text-in-dataframe/\n",
        "  df['sentence'] = df['review_title'] + \" \" + df['review']\n",
        "\n",
        "  # Remove unnecessary data columns (we just want [sentence, class])\n",
        "  return df[['sentence', 'class']]\n",
        "\n",
        "df1 = format_data(infile1)\n",
        "df2 = format_data(infile2)\n",
        "df3 = format_data(infile3)\n",
        "\n",
        "# preview each input file to ensure data looks correct\n",
        "print('File1 has', len(df1), 'rows')\n",
        "print(df1.head(5))\n",
        "print('File2 has', len(df2), 'rows')\n",
        "print(df2.head(5))\n",
        "print('File3 has', len(df3), 'rows')\n",
        "print(df3.head(5))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfR_MZ2LfYXN",
        "outputId": "5fa2b2f2-945f-48bf-a02c-5c9a6c4171c0"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File1 has 20473 rows\n",
            "                                            sentence  class\n",
            "0  Work Well - Should Have Bought Longer Ones I n...      5\n",
            "1  Okay long cables These long cables work fine f...      4\n",
            "2  Looks and feels heavy Duty Can't comment much ...      5\n",
            "3  Excellent choice for Jumper Cables!!! I absolu...      5\n",
            "4  Excellent, High Quality Starter Cables I purch...      5\n",
            "File2 has 15166 rows\n",
            "                                            sentence  class\n",
            "0  Super! 1) Camera quality : Awesome ... it gene...      5\n",
            "1  Terrific purchase Awesome mobile , I got it wi...      5\n",
            "2  Delightful Honor 10 lite :Pros :-1) Cameras ar...      4\n",
            "3  Brilliant Superb camera, beautiful and slim de...      5\n",
            "4  Must buy! good and best mobil honor is best co...      5\n",
            "File3 has 9374 rows\n",
            "                                            sentence  class\n",
            "0  Terrific purchase 1-more flexible2-bass is ver...      5\n",
            "1  Terrific purchase Super sound and good looking...      5\n",
            "2  Super! Very much satisfied with the device at ...      5\n",
            "3  Super! Nice headphone, bass was very good and ...      5\n",
            "4  Terrific purchase Sound quality super battery ...      5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# merge the data\n",
        "all_data = pandas.concat([df1, df2, df3])\n",
        "\n",
        "results = {}\n",
        "\n",
        "# how many rows?\n",
        "print(len(all_data), 'total rows loaded')\n",
        "\n",
        "# throw out any empty reviews (see https://stackoverflow.com/a/56708633)\n",
        "all_data['sentence'].replace('', np.nan, inplace=True)\n",
        "all_data.dropna(subset=['sentence'], inplace=True)\n",
        "print(len(all_data), 'rows after removing empty reviews')\n",
        "\n",
        "# Convert to dict for easier processing later\n",
        "all_data = all_data.to_dict('records')\n",
        "\n",
        "classes = [1,2,3,4,5]\n",
        "\n",
        "split1 = int(.8*len(all_data))\n",
        "split2 = int(.9*len(all_data))\n",
        "traindata = all_data[:split1]\n",
        "devdata = all_data[split1:split2]\n",
        "testdata = all_data[split2:]\n",
        "\n",
        "print(len(traindata), 'training,', len(devdata), 'dev,', len(testdata), 'test rows loaded')\n",
        "\n",
        "X_train = [row.get('sentence') for row in traindata]\n",
        "y_train = [row.get('class') for row in traindata]\n",
        "\n",
        "X_val = [row.get('sentence') for row in devdata]\n",
        "y_val = [row.get('class') for row in devdata]\n",
        "\n",
        "X_test = [row.get('sentence') for row in testdata]\n",
        "y_test = [row.get('class') for row in testdata]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Y-hN-NjLDg2",
        "outputId": "c3eaa431-f951-4a88-a486-40dbd50f08f7"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45013 total rows loaded\n",
            "45013 rows after removing empty reviews\n",
            "36010 training, 4501 dev, 4502 test rows loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate vocabulary\n",
        "vocab = set()\n",
        "tokenizer = MyTokenizer()\n",
        "\n",
        "for row in all_data:\n",
        "  row['tokens'] = tokenizer.tokenize(row['sentence'])\n",
        "  for tok in row['tokens']:\n",
        "    vocab.add(tok)\n",
        "\n",
        "# preview\n",
        "print('Found', len(vocab), 'words in vocabulary')\n",
        "for id,val in enumerate(vocab):\n",
        "  if id < 25:\n",
        "    print(val + \", \")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hX_Lls1Wq7Ji",
        "outputId": "adeba825-b0ae-4c55-86cf-1f01769c8b44"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 31120 words in vocabulary\n",
            "warrantyupd, \n",
            "pursu, \n",
            "soun, \n",
            "crappi, \n",
            "needle-nos, \n",
            "non-incandesc, \n",
            "rollback, \n",
            "rangeyou, \n",
            "-sound, \n",
            "poduct, \n",
            "vortex, \n",
            "jod, \n",
            "pre-mold, \n",
            "headlin, \n",
            "00272-sllc2, \n",
            "-best, \n",
            "maalibu, \n",
            "non-obd-ii, \n",
            "clayblock, \n",
            "betweenbear, \n",
            "rewiew, \n",
            "looki, \n",
            "venthos, \n",
            "previousali, \n",
            "dy, \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "nbc = NaiveBayesClassifier(vocab, classes, tokenizer)\n",
        "nbc.train(traindata)"
      ],
      "metadata": {
        "id": "eoILzRWQtDqm"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate probability of occurrance of each word\n",
        "vocab_probs = {}\n",
        "for word in vocab:\n",
        "  if (nbc.word_counts[word]['total'] > 0):    # if freq == 0 that means it did not appear in the training data\n",
        "    vocab_probs[word] = nbc.word_counts[word]['total'] / len(traindata)\n",
        "\n",
        "# preview: words with highest probability\n",
        "print('Top 5: words with highest probability')\n",
        "for w in sorted(vocab_probs, key=vocab_probs.get, reverse=True)[:8]:\n",
        "  print(w, vocab_probs[w])\n",
        "\n",
        "# preview: words with lowest probability\n",
        "print(\"\\n\",'Bottom 5: words with lowest probability')\n",
        "for w in sorted(vocab_probs, key=vocab_probs.get)[:8]:\n",
        "  print(w, vocab_probs[w])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFAOMotmw7OM",
        "outputId": "79411e58-10dd-4289-e826-5f9bf94140b7"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5: words with highest probability\n",
            "good 0.33832268814218275\n",
            "use 0.2915301305193002\n",
            "product 0.260483199111358\n",
            "work 0.22826992502082755\n",
            "great 0.21727297972785337\n",
            "veri 0.21627325742849207\n",
            "n't 0.1998333796167731\n",
            "nice 0.17056373229658428\n",
            "\n",
            " Bottom 5: words with lowest probability\n",
            "warrantyupd 2.7770063871146904e-05\n",
            "non-incandesc 2.7770063871146904e-05\n",
            "rollback 2.7770063871146904e-05\n",
            "jod 2.7770063871146904e-05\n",
            "pre-mold 2.7770063871146904e-05\n",
            "00272-sllc2 2.7770063871146904e-05\n",
            "maalibu 2.7770063871146904e-05\n",
            "non-obd-ii 2.7770063871146904e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preview Conditional Probabilities (computed during training)\n",
        "print('Top 5 Conditional probability')\n",
        "for w in sorted(nbc.word_probs, key=nbc.word_probs.get, reverse=True)[:5]:\n",
        "  print(w, nbc.word_probs[w])\n",
        "\n",
        "print()\n",
        "print('Bottom 5 Conditional probability')\n",
        "for w in sorted(nbc.word_probs, key=nbc.word_probs.get)[:5]:\n",
        "  print(w, nbc.word_probs[w])\n",
        "\n",
        "# Preview class probabilities\n",
        "print()\n",
        "print('Class probabilities')\n",
        "for c in classes:\n",
        "  print(c, nbc.class_probs[c])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJihGMTy09Je",
        "outputId": "48d0d521-1c57-48c1-e9a0-4d4bdcf86511"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 Conditional probability\n",
            "good__4 0.5238424326192122\n",
            "good__3 0.39270130900436334\n",
            "n't__2 0.3403041825095057\n",
            "n't__1 0.32483156881616937\n",
            "use__2 0.31749049429657794\n",
            "\n",
            "Bottom 5 Conditional probability\n",
            "warrantyupd__1 0.0\n",
            "warrantyupd__2 0.0\n",
            "warrantyupd__3 0.0\n",
            "warrantyupd__4 0.0\n",
            "pursu__1 0.0\n",
            "\n",
            "Class probabilities\n",
            "1 0.057706192724243266\n",
            "2 0.02921410719244654\n",
            "3 0.07000833101916135\n",
            "4 0.20091641210774785\n",
            "5 0.642154956956401\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# try predicting labels for test data\n",
        "Y_hat = nbc.predict(testdata)"
      ],
      "metadata": {
        "id": "YtIkSVK9-iLk"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print('Responsibility predictions:', len([y for y in Y_hat if y == 'Responsibility']))\n",
        "#print('SoftSkill predictions:', len([y for y in Y_hat if y == 'SoftSkill']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9MQIr9DHEZL",
        "outputId": "f4c267f6-d064-4aa2-a55e-28f24a90f230"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Responsibility predictions: 14045\n",
            "SoftSkill predictions: 3754\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate accuracy\n",
        "def calculate_accuracy(Y, Y_hat):\n",
        "  num_correct = 0\n",
        "  index=0\n",
        "  if len(Y) != len(Y_hat):\n",
        "    print('data invalid length', len(Y), ':', len(Y_hat))\n",
        "    return False\n",
        "  for row in Y:\n",
        "    y_hat = Y_hat[index]\n",
        "    y = row['class']\n",
        "    num_correct += 1 if y_hat == y else 0\n",
        "    index += 1\n",
        "  return num_correct / len(Y)\n",
        "\n",
        "#accuracy = calculate_accuracy(y_test, Y_hat)\n",
        "\n",
        "#print('Accuracy for Dev data:', accuracy)\n",
        "results['nbc'] = classification_report(y_test, Y_hat, output_dict=True)\n",
        "print(classification_report(y_test, Y_hat))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "se5s7pAhBT0z",
        "outputId": "c737e952-d8e7-42fb-ac96-e18b265917bb"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.29      0.72      0.41       530\n",
            "           2       0.53      0.41      0.46       175\n",
            "           3       0.56      0.36      0.44       368\n",
            "           4       0.59      0.56      0.57       963\n",
            "           5       0.85      0.66      0.74      2466\n",
            "\n",
            "    accuracy                           0.61      4502\n",
            "   macro avg       0.56      0.54      0.53      4502\n",
            "weighted avg       0.69      0.61      0.63      4502\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare the result with smoothing\n",
        "nbc2 = NaiveBayesClassifier(vocab, classes, tokenizer)\n",
        "nbc2.use_smoothing = True\n",
        "nbc2.train(traindata)\n",
        "\n",
        "Y_hat = nbc2.predict(testdata)\n",
        "#accuracy = calculate_accuracy(Y, Y_hat)\n",
        "\n",
        "#print('Accuracy with smoothing:', accuracy)\n",
        "\n",
        "results['nbc2'] = classification_report(y_test, Y_hat, output_dict=True)\n",
        "print(classification_report(y_test, Y_hat))\n"
      ],
      "metadata": {
        "id": "0aJODZdgLNlS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6e4ff29-f3f7-478d-b87b-2af741d6bd3f"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.03      0.05       530\n",
            "           2       0.00      0.00      0.00       175\n",
            "           3       1.00      0.00      0.01       368\n",
            "           4       0.99      0.09      0.16       963\n",
            "           5       0.56      1.00      0.72      2466\n",
            "\n",
            "    accuracy                           0.57      4502\n",
            "   macro avg       0.71      0.22      0.19      4502\n",
            "weighted avg       0.72      0.57      0.43      4502\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare with Decision Tree Approach\n",
        "# ref: https://www.codementor.io/blog/text-classification-6mmol0q8oj\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "X_train_v = vectorizer.fit_transform(X_train)\n",
        "#y_train_v = vectorizer.transform(y_train)"
      ],
      "metadata": {
        "id": "Un-_NUKQGdzL"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build decision tree based on training data\n",
        "dt = tree.DecisionTreeClassifier()\n",
        "dt.fit(X_train_v, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xtzj_2NaNfpq",
        "outputId": "ff622a09-b34a-460c-ab6c-7c6cf29e9c46"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier()"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the decision tree\n",
        "X_test_v = vectorizer.transform(X_test)\n",
        "y_pred = dt.predict(X_test_v)\n",
        "\n",
        "results['dt'] = classification_report(y_test, y_pred, output_dict=True)\n",
        "print(classification_report(y_test, y_pred))\n",
        "#print(confusion_matrix(y_val, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBXPnv3gH3rt",
        "outputId": "6eb28911-9b1e-44fd-e40d-8788ff9a0cdc"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.93      0.79      0.85       530\n",
            "           2       0.67      0.53      0.59       175\n",
            "           3       0.68      0.51      0.59       368\n",
            "           4       0.65      0.74      0.69       963\n",
            "           5       0.84      0.87      0.86      2466\n",
            "\n",
            "    accuracy                           0.79      4502\n",
            "   macro avg       0.76      0.69      0.72      4502\n",
            "weighted avg       0.79      0.79      0.79      4502\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM\n",
        "# ref: https://www.codementor.io/blog/text-classification-6mmol0q8oj\n",
        "\n",
        "svm = LinearSVC()\n",
        "_ = svm.fit(X_train_v, y_train)\n",
        "y_pred = svm.predict(X_test_v)\n",
        "\n",
        "results['svm'] = classification_report(y_test, y_pred, output_dict=True)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ye-vQLQxMRrY",
        "outputId": "6570870d-4a53-4d8a-ac07-ffa48d65dcbf"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.96      0.95      0.96       530\n",
            "           2       0.84      0.78      0.81       175\n",
            "           3       0.83      0.62      0.71       368\n",
            "           4       0.77      0.74      0.76       963\n",
            "           5       0.90      0.95      0.92      2466\n",
            "\n",
            "    accuracy                           0.87      4502\n",
            "   macro avg       0.86      0.81      0.83      4502\n",
            "weighted avg       0.87      0.87      0.87      4502\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r1 = classification_report(y_test, y_pred, output_dict=True)\n",
        "r1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WymZXbiEZPBk",
        "outputId": "de1cf5e8-13ce-460e-cea7-19459d32857f"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'1': {'precision': 0.9637404580152672,\n",
              "  'recall': 0.9528301886792453,\n",
              "  'f1-score': 0.9582542694497154,\n",
              "  'support': 530},\n",
              " '2': {'precision': 0.8404907975460123,\n",
              "  'recall': 0.7828571428571428,\n",
              "  'f1-score': 0.8106508875739644,\n",
              "  'support': 175},\n",
              " '3': {'precision': 0.8260869565217391,\n",
              "  'recall': 0.6195652173913043,\n",
              "  'f1-score': 0.7080745341614906,\n",
              "  'support': 368},\n",
              " '4': {'precision': 0.767416934619507,\n",
              "  'recall': 0.7435098650051921,\n",
              "  'f1-score': 0.7552742616033756,\n",
              "  'support': 963},\n",
              " '5': {'precision': 0.8960092095165004,\n",
              "  'recall': 0.9468775344687753,\n",
              "  'f1-score': 0.9207413249211357,\n",
              "  'support': 2466},\n",
              " 'accuracy': 0.8709462461128388,\n",
              " 'macro avg': {'precision': 0.8587488712438052,\n",
              "  'recall': 0.809127989680332,\n",
              "  'f1-score': 0.8305990555419364,\n",
              "  'support': 4502},\n",
              " 'weighted avg': {'precision': 0.8686027434528918,\n",
              "  'recall': 0.8709462461128388,\n",
              "  'f1-score': 0.8681002483084835,\n",
              "  'support': 4502}}"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NN\n",
        "# ref: https://www.tensorflow.org/tutorials/keras/text_classification\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "raw_train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "raw_train_ds = raw_train_ds.batch(batch_size)\n",
        "\n",
        "raw_val_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
        "raw_val_ds = raw_val_ds.batch(batch_size)\n",
        "\n",
        "raw_test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
        "raw_test_ds = raw_test_ds.batch(batch_size)"
      ],
      "metadata": {
        "id": "s9ewl-tjUGun"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preview train data\n",
        "for text_batch, label_batch in raw_train_ds.take(1):\n",
        "  for i in range(5):\n",
        "    print(\"Sentence\", text_batch.numpy()[i])\n",
        "    print(\"Rating\", label_batch.numpy()[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdXoQSIwYKdl",
        "outputId": "433d5d4c-f7d7-4a9a-db15-bb7d4b53a870"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence b\"Work Well - Should Have Bought Longer Ones I needed a set of jumper cables for my new car and these had good reviews and were at a good price.  They have been used a few times already and do what they are supposed to - no complaints there.What I will say is that 12 feet really isn't an ideal length.  Sure, if you pull up front bumper to front bumper they are plenty long, but a lot of times you will be beside another car or can't get really close.  Because of this, I would recommend something a little longer than 12'.Great brand - get 16' version though.\"\n",
            "Rating 5\n",
            "Sentence b'Okay long cables These long cables work fine for my truck, but the quality seems a little on the shabby side. For the money I was not expecting 200 dollar snap-on jumper cables but these seem more like what you would see at a chinese knock off shop like harbor freight for 30 bucks.'\n",
            "Rating 4\n",
            "Sentence b\"Looks and feels heavy Duty Can't comment much on these since they have not yet been used (I will come back and update my review is I find any issues after first use) ... but they are built solid, nice tough big hard clamps and love having a long cable so I never have to move cars around or anything if needed. I bought these to have in my new truck since you always need cables ... but another reason is for when I tow my travel trailer and we run the batteries with no shore power they may die after a couple days ... if you are in need a quick small recharge they are the perfect length to pop my hood, run the cables to the back of the truck and hook up to the batteries that are on the tongue of my travel trailer ... running the truck for 30-45 minutes with this nice large gauge wire connected from my battery tot he trailer battery will give me a bit of a charge if ever in a pinch and I have no shore power, solar, or generator to recharge.Bought the bucket boss 06009 jumper cable bag and it fit this 25 footer Perfectly!!!It has no use and is a waste of money right now ... but will EASILY pay for itself the first time you need it ... always be prepared! :)\"\n",
            "Rating 5\n",
            "Sentence b'Excellent choice for Jumper Cables!!! I absolutley love Amazon!!!  For the price of a set of cheap Booster/Jumper Cables in a brick and morter store, you can buy extra long and heavy duty jumpers!  First off, don\\'t be the person that not only needs to ask a kind passer-by for a \"jump\" but also if they have jumper cables.  It\\'s MUCH easier to get a jump start if you have your own cables.Next lets talk about sizing.  Having the longest cable possible is a major plus if your car is parked up against something like a pole or wall, or even parked on a one way street.  The \"booster car\" (the car w/o a dead battery) can pull in close enough to use the cables without having to manuver into some akward position.  Or better yet, you won\\'t have to push your vehicle into a position to be jumped.  If your diving a normal sized car they can even pull in behind you to jump you!  Or if their vehicle is the shorter of the two, they could pull in front.  Now how about gauge?  For those who aren\\'t electricians or engineers, as the number value of gauge decreases, the size and capacity of the cable increases.  So for example 6-ga has about twice as much copper wire as 8-ga, and 4-ga is a about twice as much as 6-ga, so on and so on.  That doesn\\'t mean you double the capacity of wire with every two numbers though.  4-gauge may sound like a lot but it really isn\\'t.The technical stuff.  Don\\'t worry if this doesn\\'t make sense, you don\\'t really need to know all of this, but I\\'m trying to make a point as to why to get the longest and heavist cables you can.  I\\'m not an electrican but I\\'ve worked with it long enough to know a few general rules of thumb.  First of the enemy of electricty is resistance.  Resistance ultimately determines the load a particular wire can carry.  Five things factor into resistance.  Temperature, conductor, voltage, load, and distance.  Temp we can\\'t control, so we have to assume the worst (HOT)...or in other words need heavier cable.  Conductor should be copper, or at least a high purity mix of copper...good there.  Voltage...12VDC is a low voltage system...probably the biggest problem we face.  Since is a low voltage system we have to contend with voltage drop as it travels over the wire.  The higher the voltage, the longer it can run with acceptable levels of voltage drop over a particular gauge wire...so again since it\\'s low voltage need heavier gauge wire.  Load (Amperage)...it\\'s a car starter so it takes A LOT of power.  The voltage is a fixed number (more or less) so Amperage is determined by the size of the engine your trying to start.  And you\\'d be surprised how high that can be.  Even a small engine can be well over 300 Cranking Amps.  That said even a \"dead\" battery will put out some power.  As for distance...this cables selling point is also a draw back.  25\\' is LONG run for 12VDC.  So like I said in the last line 4-ga isn\\'t as much as you think.  In fact, if you have an engine over 6-liters you should really consider 2-ga for this distance.  So summing up in layman\\'s terms...considering the hot temperatures outside, the fact that it\\'s 12VDC and we need a long cable, and that we\\'re trying to start a car engine (which takes a LOT of power) these are the ONLY cables I could reccomend for anyone driving a small car up to a light truck.Lets talk about how to properly start a car with a drained battery.  Make sure the LAST connection make is the NEG clamp to the \"dead\" car on a frame ground (something metal and NOT MOVING or GOING TO MOVE in the engine compartment.)  Don\\'t attach it directly to the battery\\'s NEG post.  Next lightly rev the engine of the running vehicle for 3 to 5 minutes.  This will put a bit of a surface charge on the dead battery.  Then attempt to start the car.  As soon as it starts remove the cables (starting with the NEG on the car being jumped.)  If you ever have a dead battery for any reason...take it to an auto parts store as soon as possible and have it tested to make sure it still holds a proper charge.  Most places do it for free.  NEVER touch the clamps together once connected to a battery!!!  Doing so could damage you vehicles electrical system, and/or cause fire, burns, explosion of the battery, damages to your cables...A couple of final thoughts.  Protect your investment.  I bought a cable bag that works really well to keep them from getting tangled with everything in my trunk.  Also keep the twist ties that come with them which will keep them organized inside the cable bag.  And once used, take them home and clean and dry them before storing them once again.  The oils inside of engine compartments can be corrosive to rubber jackets and copper contacts.  These cables are more than worth they weight in gold!  They are inexpensive and top notch quality!'\n",
            "Rating 5\n",
            "Sentence b\"Excellent, High Quality Starter Cables I purchased the 12' feet long cable set and they arrived in a retail cardboard box with handle, which could be used as a storage and carrying case for these cables, although I will not need to store them with the carry box.  These are high quality long cables of high grade materials and I believe worth the price I paid for them.  They will store in the back seat storage compartment of my truck easily.  Recomend.\"\n",
            "Rating 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_features = 10000\n",
        "sequence_length = 250\n",
        "\n",
        "vectorize_layer = layers.TextVectorization(\n",
        "    max_tokens=max_features,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=sequence_length)\n",
        "\n",
        "# Make a text-only dataset (without labels), then call adapt\n",
        "train_text = raw_train_ds.map(lambda x, y: x)\n",
        "vectorize_layer.adapt(train_text)\n",
        "\n",
        "def vectorize_text(text, label):\n",
        "  text = tf.expand_dims(text, -1)\n",
        "  return vectorize_layer(text), label\n"
      ],
      "metadata": {
        "id": "FyMwlZavY_Kb"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preview a vectorized item from the dataset\n",
        "text_batch, label_batch = next(iter(raw_train_ds))\n",
        "first_review, first_label = text_batch[0], label_batch[0]\n",
        "print(\"Review\", first_review)\n",
        "print(\"Label\", first_label)\n",
        "print(\"Vectorized review\", vectorize_text(first_review, first_label))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eP1sZW6LZ5cj",
        "outputId": "edf304e7-794f-42ff-c4e5-a51b59a3f54f"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review tf.Tensor(b\"Work Well - Should Have Bought Longer Ones I needed a set of jumper cables for my new car and these had good reviews and were at a good price.  They have been used a few times already and do what they are supposed to - no complaints there.What I will say is that 12 feet really isn't an ideal length.  Sure, if you pull up front bumper to front bumper they are plenty long, but a lot of times you will be beside another car or can't get really close.  Because of this, I would recommend something a little longer than 12'.Great brand - get 16' version though.\", shape=(), dtype=string)\n",
            "Label tf.Tensor(5, shape=(), dtype=int32)\n",
            "Vectorized review (<tf.Tensor: shape=(1, 250), dtype=int64, numpy=\n",
            "array([[  72,   44,  142,   21,  104,  330,  331,    6,  227,    5,  219,\n",
            "          10, 2057,  734,   11,   14,  111,   33,    3,   34,   59,   18,\n",
            "         380,    3,  137,   42,    5,   18,   65,   31,   21,  112,   54,\n",
            "           5,  153,  309,  509,    3,   62,   83,   31,   24,  727,    4,\n",
            "          52, 1264,    1,    6,   39,  192,    8,   15,  450, 1145,   74,\n",
            "         421,   63, 1931,  774,  135,   36,   16,  545,   48,  248,  770,\n",
            "           4,  248,  770,   31,   24,  925,  109,   20,    5,  164,   10,\n",
            "         309,   16,   39,   30, 5245,  206,   33,   40,  202,   57,   74,\n",
            "         628,  101,   10,    9,    6,   60,  136,  269,    5,   90,  330,\n",
            "          55,    1,  338,   57, 1048,  760,  270,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0]])>, <tf.Tensor: shape=(), dtype=int32, numpy=5>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# apply the TextVectorization layer  to datasets\n",
        "train_ds = raw_train_ds.map(vectorize_text)\n",
        "val_ds = raw_val_ds.map(vectorize_text)\n",
        "test_ds = raw_test_ds.map(vectorize_text)\n",
        "\n",
        "# configure for performance\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "r3QZsW1RaiVi"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preview train_ds again\n",
        "text_batch, label_batch = next(iter(train_ds))\n",
        "first_review, first_label = text_batch[0], label_batch[0]\n",
        "print(\"Review\", first_review)\n",
        "print(\"Label\", first_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Lnb0ctHW60C",
        "outputId": "35031fb0-e9b7-48b4-a647-070ccf241467"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review tf.Tensor(\n",
            "[  72   44  142   21  104  330  331    6  227    5  219   10 2057  734\n",
            "   11   14  111   33    3   34   59   18  380    3  137   42    5   18\n",
            "   65   31   21  112   54    5  153  309  509    3   62   83   31   24\n",
            "  727    4   52 1264    1    6   39  192    8   15  450 1145   74  421\n",
            "   63 1931  774  135   36   16  545   48  248  770    4  248  770   31\n",
            "   24  925  109   20    5  164   10  309   16   39   30 5245  206   33\n",
            "   40  202   57   74  628  101   10    9    6   60  136  269    5   90\n",
            "  330   55    1  338   57 1048  760  270    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0], shape=(250,), dtype=int64)\n",
            "Label tf.Tensor(5, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# build a model\n",
        "embedding_dim = 16\n",
        "\n",
        "ann = tf.keras.Sequential([\n",
        "  layers.Embedding(max_features + 1, embedding_dim),\n",
        "  layers.Dropout(0.2),\n",
        "  layers.GlobalAveragePooling1D(),\n",
        "  layers.Dropout(0.2),\n",
        "  layers.Dense(1)])\n",
        "\n",
        "ann.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERbNoxDbar2Z",
        "outputId": "0cbd383d-4cfe-4a1c-8b10-13f2502947e6"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, None, 16)          160016    \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, None, 16)          0         \n",
            "                                                                 \n",
            " global_average_pooling1d_1   (None, 16)               0         \n",
            " (GlobalAveragePooling1D)                                        \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 16)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 160,033\n",
            "Trainable params: 160,033\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "ann.compile(loss=losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer='adam',\n",
        "              metrics=tf.metrics.BinaryAccuracy(threshold=0.0))\n",
        "\n",
        "# train the model\n",
        "epochs = 10\n",
        "history = ann.fit(train_ds, validation_data=val_ds, epochs=epochs)\n",
        "#history = ann.fit(train_ds, epochs=epochs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wNLhEiJazh2",
        "outputId": "9e472a64-963c-4336-c5a6-3a6c8ec66bdc"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1126/1126 [==============================] - 14s 11ms/step - loss: -25350.2285 - binary_accuracy: 0.0577 - val_loss: -26340.7949 - val_binary_accuracy: 0.1169\n",
            "Epoch 2/10\n",
            "1126/1126 [==============================] - 7s 6ms/step - loss: -27911.6895 - binary_accuracy: 0.0577 - val_loss: -28955.2988 - val_binary_accuracy: 0.1169\n",
            "Epoch 3/10\n",
            "1126/1126 [==============================] - 7s 6ms/step - loss: -30562.0742 - binary_accuracy: 0.0577 - val_loss: -31706.7949 - val_binary_accuracy: 0.1169\n",
            "Epoch 4/10\n",
            "1126/1126 [==============================] - 7s 6ms/step - loss: -33477.7734 - binary_accuracy: 0.0577 - val_loss: -34595.2969 - val_binary_accuracy: 0.1169\n",
            "Epoch 5/10\n",
            "1126/1126 [==============================] - 7s 6ms/step - loss: -36476.6250 - binary_accuracy: 0.0577 - val_loss: -37608.9492 - val_binary_accuracy: 0.1169\n",
            "Epoch 6/10\n",
            "1126/1126 [==============================] - 7s 6ms/step - loss: -39524.8906 - binary_accuracy: 0.0577 - val_loss: -40741.2734 - val_binary_accuracy: 0.1169\n",
            "Epoch 7/10\n",
            "1126/1126 [==============================] - 7s 6ms/step - loss: -42733.9648 - binary_accuracy: 0.0577 - val_loss: -43996.9883 - val_binary_accuracy: 0.1169\n",
            "Epoch 8/10\n",
            "1126/1126 [==============================] - 7s 6ms/step - loss: -46102.7891 - binary_accuracy: 0.0577 - val_loss: -47374.7188 - val_binary_accuracy: 0.1169\n",
            "Epoch 9/10\n",
            "1126/1126 [==============================] - 7s 6ms/step - loss: -49586.7109 - binary_accuracy: 0.0577 - val_loss: -50874.2930 - val_binary_accuracy: 0.1169\n",
            "Epoch 10/10\n",
            "1126/1126 [==============================] - 7s 6ms/step - loss: -53152.8203 - binary_accuracy: 0.0577 - val_loss: -54492.3945 - val_binary_accuracy: 0.1169\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = ann.predict(test_ds)\n",
        "print(classification_report(y_test, y_pred.astype(int)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_fgXJpUVczU",
        "outputId": "90aea2f9-4728-4d17-9e74-1ccb574cf3c1"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "141/141 [==============================] - 1s 4ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.00      0.00      0.00     530.0\n",
            "           2       0.00      0.00      0.00     175.0\n",
            "           3       0.00      0.00      0.00     368.0\n",
            "           4       0.00      0.00      0.00     963.0\n",
            "           5       0.00      0.00      0.00    2466.0\n",
            "       14660       0.00      0.00      0.00       0.0\n",
            "       14687       0.00      0.00      0.00       0.0\n",
            "       14750       0.00      0.00      0.00       0.0\n",
            "       14759       0.00      0.00      0.00       0.0\n",
            "       14796       0.00      0.00      0.00       0.0\n",
            "       14827       0.00      0.00      0.00       0.0\n",
            "       14842       0.00      0.00      0.00       0.0\n",
            "       14850       0.00      0.00      0.00       0.0\n",
            "       14863       0.00      0.00      0.00       0.0\n",
            "       14896       0.00      0.00      0.00       0.0\n",
            "       14902       0.00      0.00      0.00       0.0\n",
            "       14909       0.00      0.00      0.00       0.0\n",
            "       14940       0.00      0.00      0.00       0.0\n",
            "       14956       0.00      0.00      0.00       0.0\n",
            "       14976       0.00      0.00      0.00       0.0\n",
            "       14989       0.00      0.00      0.00       0.0\n",
            "       14997       0.00      0.00      0.00       0.0\n",
            "       15011       0.00      0.00      0.00       0.0\n",
            "       15012       0.00      0.00      0.00       0.0\n",
            "       15068       0.00      0.00      0.00       0.0\n",
            "       15074       0.00      0.00      0.00       0.0\n",
            "       15078       0.00      0.00      0.00       0.0\n",
            "       15083       0.00      0.00      0.00       0.0\n",
            "       15095       0.00      0.00      0.00       0.0\n",
            "       15098       0.00      0.00      0.00       0.0\n",
            "       15102       0.00      0.00      0.00       0.0\n",
            "       15104       0.00      0.00      0.00       0.0\n",
            "       15110       0.00      0.00      0.00       0.0\n",
            "       15111       0.00      0.00      0.00       0.0\n",
            "       15136       0.00      0.00      0.00       0.0\n",
            "       15146       0.00      0.00      0.00       0.0\n",
            "       15154       0.00      0.00      0.00       0.0\n",
            "       15162       0.00      0.00      0.00       0.0\n",
            "       15163       0.00      0.00      0.00       0.0\n",
            "       15173       0.00      0.00      0.00       0.0\n",
            "       15174       0.00      0.00      0.00       0.0\n",
            "       15178       0.00      0.00      0.00       0.0\n",
            "       15181       0.00      0.00      0.00       0.0\n",
            "       15186       0.00      0.00      0.00       0.0\n",
            "       15192       0.00      0.00      0.00       0.0\n",
            "       15193       0.00      0.00      0.00       0.0\n",
            "       15196       0.00      0.00      0.00       0.0\n",
            "       15197       0.00      0.00      0.00       0.0\n",
            "       15210       0.00      0.00      0.00       0.0\n",
            "       15213       0.00      0.00      0.00       0.0\n",
            "       15218       0.00      0.00      0.00       0.0\n",
            "       15239       0.00      0.00      0.00       0.0\n",
            "       15246       0.00      0.00      0.00       0.0\n",
            "       15260       0.00      0.00      0.00       0.0\n",
            "       15261       0.00      0.00      0.00       0.0\n",
            "       15271       0.00      0.00      0.00       0.0\n",
            "       15287       0.00      0.00      0.00       0.0\n",
            "       15288       0.00      0.00      0.00       0.0\n",
            "       15293       0.00      0.00      0.00       0.0\n",
            "       15303       0.00      0.00      0.00       0.0\n",
            "       15314       0.00      0.00      0.00       0.0\n",
            "       15316       0.00      0.00      0.00       0.0\n",
            "       15317       0.00      0.00      0.00       0.0\n",
            "       15319       0.00      0.00      0.00       0.0\n",
            "       15320       0.00      0.00      0.00       0.0\n",
            "       15321       0.00      0.00      0.00       0.0\n",
            "       15322       0.00      0.00      0.00       0.0\n",
            "       15357       0.00      0.00      0.00       0.0\n",
            "       15358       0.00      0.00      0.00       0.0\n",
            "       15373       0.00      0.00      0.00       0.0\n",
            "       15377       0.00      0.00      0.00       0.0\n",
            "       15383       0.00      0.00      0.00       0.0\n",
            "       15388       0.00      0.00      0.00       0.0\n",
            "       15391       0.00      0.00      0.00       0.0\n",
            "       15394       0.00      0.00      0.00       0.0\n",
            "       15402       0.00      0.00      0.00       0.0\n",
            "       15411       0.00      0.00      0.00       0.0\n",
            "       15423       0.00      0.00      0.00       0.0\n",
            "       15433       0.00      0.00      0.00       0.0\n",
            "       15439       0.00      0.00      0.00       0.0\n",
            "       15444       0.00      0.00      0.00       0.0\n",
            "       15446       0.00      0.00      0.00       0.0\n",
            "       15462       0.00      0.00      0.00       0.0\n",
            "       15466       0.00      0.00      0.00       0.0\n",
            "       15472       0.00      0.00      0.00       0.0\n",
            "       15481       0.00      0.00      0.00       0.0\n",
            "       15489       0.00      0.00      0.00       0.0\n",
            "       15492       0.00      0.00      0.00       0.0\n",
            "       15497       0.00      0.00      0.00       0.0\n",
            "       15503       0.00      0.00      0.00       0.0\n",
            "       15506       0.00      0.00      0.00       0.0\n",
            "       15511       0.00      0.00      0.00       0.0\n",
            "       15512       0.00      0.00      0.00       0.0\n",
            "       15519       0.00      0.00      0.00       0.0\n",
            "       15524       0.00      0.00      0.00       0.0\n",
            "       15525       0.00      0.00      0.00       0.0\n",
            "       15534       0.00      0.00      0.00       0.0\n",
            "       15535       0.00      0.00      0.00       0.0\n",
            "       15538       0.00      0.00      0.00       0.0\n",
            "       15558       0.00      0.00      0.00       0.0\n",
            "       15565       0.00      0.00      0.00       0.0\n",
            "       15570       0.00      0.00      0.00       0.0\n",
            "       15578       0.00      0.00      0.00       0.0\n",
            "       15595       0.00      0.00      0.00       0.0\n",
            "       15597       0.00      0.00      0.00       0.0\n",
            "       15600       0.00      0.00      0.00       0.0\n",
            "       15611       0.00      0.00      0.00       0.0\n",
            "       15614       0.00      0.00      0.00       0.0\n",
            "       15615       0.00      0.00      0.00       0.0\n",
            "       15618       0.00      0.00      0.00       0.0\n",
            "       15629       0.00      0.00      0.00       0.0\n",
            "       15636       0.00      0.00      0.00       0.0\n",
            "       15650       0.00      0.00      0.00       0.0\n",
            "       15673       0.00      0.00      0.00       0.0\n",
            "       15679       0.00      0.00      0.00       0.0\n",
            "       15707       0.00      0.00      0.00       0.0\n",
            "       15708       0.00      0.00      0.00       0.0\n",
            "       15720       0.00      0.00      0.00       0.0\n",
            "       15740       0.00      0.00      0.00       0.0\n",
            "       15741       0.00      0.00      0.00       0.0\n",
            "       15744       0.00      0.00      0.00       0.0\n",
            "       15756       0.00      0.00      0.00       0.0\n",
            "       15762       0.00      0.00      0.00       0.0\n",
            "       15769       0.00      0.00      0.00       0.0\n",
            "       15772       0.00      0.00      0.00       0.0\n",
            "       15780       0.00      0.00      0.00       0.0\n",
            "       15790       0.00      0.00      0.00       0.0\n",
            "       15792       0.00      0.00      0.00       0.0\n",
            "       15794       0.00      0.00      0.00       0.0\n",
            "       15796       0.00      0.00      0.00       0.0\n",
            "       15809       0.00      0.00      0.00       0.0\n",
            "       15833       0.00      0.00      0.00       0.0\n",
            "       15850       0.00      0.00      0.00       0.0\n",
            "       15861       0.00      0.00      0.00       0.0\n",
            "       15862       0.00      0.00      0.00       0.0\n",
            "       15876       0.00      0.00      0.00       0.0\n",
            "       15878       0.00      0.00      0.00       0.0\n",
            "       15890       0.00      0.00      0.00       0.0\n",
            "       15893       0.00      0.00      0.00       0.0\n",
            "       15895       0.00      0.00      0.00       0.0\n",
            "       15905       0.00      0.00      0.00       0.0\n",
            "       15924       0.00      0.00      0.00       0.0\n",
            "       15926       0.00      0.00      0.00       0.0\n",
            "       15936       0.00      0.00      0.00       0.0\n",
            "       15938       0.00      0.00      0.00       0.0\n",
            "       15940       0.00      0.00      0.00       0.0\n",
            "       15949       0.00      0.00      0.00       0.0\n",
            "       15954       0.00      0.00      0.00       0.0\n",
            "       15957       0.00      0.00      0.00       0.0\n",
            "       15958       0.00      0.00      0.00       0.0\n",
            "       15968       0.00      0.00      0.00       0.0\n",
            "       15969       0.00      0.00      0.00       0.0\n",
            "       15971       0.00      0.00      0.00       0.0\n",
            "       15988       0.00      0.00      0.00       0.0\n",
            "       15989       0.00      0.00      0.00       0.0\n",
            "       15992       0.00      0.00      0.00       0.0\n",
            "       15997       0.00      0.00      0.00       0.0\n",
            "       16005       0.00      0.00      0.00       0.0\n",
            "       16009       0.00      0.00      0.00       0.0\n",
            "       16013       0.00      0.00      0.00       0.0\n",
            "       16014       0.00      0.00      0.00       0.0\n",
            "       16017       0.00      0.00      0.00       0.0\n",
            "       16019       0.00      0.00      0.00       0.0\n",
            "       16025       0.00      0.00      0.00       0.0\n",
            "       16027       0.00      0.00      0.00       0.0\n",
            "       16033       0.00      0.00      0.00       0.0\n",
            "       16040       0.00      0.00      0.00       0.0\n",
            "       16041       0.00      0.00      0.00       0.0\n",
            "       16054       0.00      0.00      0.00       0.0\n",
            "       16055       0.00      0.00      0.00       0.0\n",
            "       16061       0.00      0.00      0.00       0.0\n",
            "       16063       0.00      0.00      0.00       0.0\n",
            "       16064       0.00      0.00      0.00       0.0\n",
            "       16068       0.00      0.00      0.00       0.0\n",
            "       16079       0.00      0.00      0.00       0.0\n",
            "       16094       0.00      0.00      0.00       0.0\n",
            "       16096       0.00      0.00      0.00       0.0\n",
            "       16097       0.00      0.00      0.00       0.0\n",
            "       16099       0.00      0.00      0.00       0.0\n",
            "       16102       0.00      0.00      0.00       0.0\n",
            "       16105       0.00      0.00      0.00       0.0\n",
            "       16111       0.00      0.00      0.00       0.0\n",
            "       16112       0.00      0.00      0.00       0.0\n",
            "       16118       0.00      0.00      0.00       0.0\n",
            "       16137       0.00      0.00      0.00       0.0\n",
            "       16139       0.00      0.00      0.00       0.0\n",
            "       16143       0.00      0.00      0.00       0.0\n",
            "       16148       0.00      0.00      0.00       0.0\n",
            "       16153       0.00      0.00      0.00       0.0\n",
            "       16159       0.00      0.00      0.00       0.0\n",
            "       16167       0.00      0.00      0.00       0.0\n",
            "       16173       0.00      0.00      0.00       0.0\n",
            "       16178       0.00      0.00      0.00       0.0\n",
            "       16197       0.00      0.00      0.00       0.0\n",
            "       16207       0.00      0.00      0.00       0.0\n",
            "       16210       0.00      0.00      0.00       0.0\n",
            "       16213       0.00      0.00      0.00       0.0\n",
            "       16218       0.00      0.00      0.00       0.0\n",
            "       16226       0.00      0.00      0.00       0.0\n",
            "       16234       0.00      0.00      0.00       0.0\n",
            "       16236       0.00      0.00      0.00       0.0\n",
            "       16241       0.00      0.00      0.00       0.0\n",
            "       16242       0.00      0.00      0.00       0.0\n",
            "       16249       0.00      0.00      0.00       0.0\n",
            "       16251       0.00      0.00      0.00       0.0\n",
            "       16263       0.00      0.00      0.00       0.0\n",
            "       16269       0.00      0.00      0.00       0.0\n",
            "       16270       0.00      0.00      0.00       0.0\n",
            "       16271       0.00      0.00      0.00       0.0\n",
            "       16274       0.00      0.00      0.00       0.0\n",
            "       16286       0.00      0.00      0.00       0.0\n",
            "       16288       0.00      0.00      0.00       0.0\n",
            "       16289       0.00      0.00      0.00       0.0\n",
            "       16290       0.00      0.00      0.00       0.0\n",
            "       16293       0.00      0.00      0.00       0.0\n",
            "       16298       0.00      0.00      0.00       0.0\n",
            "       16299       0.00      0.00      0.00       0.0\n",
            "       16305       0.00      0.00      0.00       0.0\n",
            "       16314       0.00      0.00      0.00       0.0\n",
            "       16315       0.00      0.00      0.00       0.0\n",
            "       16319       0.00      0.00      0.00       0.0\n",
            "       16320       0.00      0.00      0.00       0.0\n",
            "       16322       0.00      0.00      0.00       0.0\n",
            "       16330       0.00      0.00      0.00       0.0\n",
            "       16332       0.00      0.00      0.00       0.0\n",
            "       16336       0.00      0.00      0.00       0.0\n",
            "       16341       0.00      0.00      0.00       0.0\n",
            "       16342       0.00      0.00      0.00       0.0\n",
            "       16344       0.00      0.00      0.00       0.0\n",
            "       16346       0.00      0.00      0.00       0.0\n",
            "       16348       0.00      0.00      0.00       0.0\n",
            "       16351       0.00      0.00      0.00       0.0\n",
            "       16358       0.00      0.00      0.00       0.0\n",
            "       16361       0.00      0.00      0.00       0.0\n",
            "       16364       0.00      0.00      0.00       0.0\n",
            "       16367       0.00      0.00      0.00       0.0\n",
            "       16370       0.00      0.00      0.00       0.0\n",
            "       16382       0.00      0.00      0.00       0.0\n",
            "       16383       0.00      0.00      0.00       0.0\n",
            "       16394       0.00      0.00      0.00       0.0\n",
            "       16396       0.00      0.00      0.00       0.0\n",
            "       16397       0.00      0.00      0.00       0.0\n",
            "       16400       0.00      0.00      0.00       0.0\n",
            "       16402       0.00      0.00      0.00       0.0\n",
            "       16403       0.00      0.00      0.00       0.0\n",
            "       16404       0.00      0.00      0.00       0.0\n",
            "       16409       0.00      0.00      0.00       0.0\n",
            "       16411       0.00      0.00      0.00       0.0\n",
            "       16412       0.00      0.00      0.00       0.0\n",
            "       16414       0.00      0.00      0.00       0.0\n",
            "       16415       0.00      0.00      0.00       0.0\n",
            "       16417       0.00      0.00      0.00       0.0\n",
            "       16418       0.00      0.00      0.00       0.0\n",
            "       16419       0.00      0.00      0.00       0.0\n",
            "       16424       0.00      0.00      0.00       0.0\n",
            "       16427       0.00      0.00      0.00       0.0\n",
            "       16430       0.00      0.00      0.00       0.0\n",
            "       16431       0.00      0.00      0.00       0.0\n",
            "       16434       0.00      0.00      0.00       0.0\n",
            "       16438       0.00      0.00      0.00       0.0\n",
            "       16439       0.00      0.00      0.00       0.0\n",
            "       16441       0.00      0.00      0.00       0.0\n",
            "       16442       0.00      0.00      0.00       0.0\n",
            "       16443       0.00      0.00      0.00       0.0\n",
            "       16448       0.00      0.00      0.00       0.0\n",
            "       16451       0.00      0.00      0.00       0.0\n",
            "       16453       0.00      0.00      0.00       0.0\n",
            "       16454       0.00      0.00      0.00       0.0\n",
            "       16455       0.00      0.00      0.00       0.0\n",
            "       16458       0.00      0.00      0.00       0.0\n",
            "       16461       0.00      0.00      0.00       0.0\n",
            "       16466       0.00      0.00      0.00       0.0\n",
            "       16477       0.00      0.00      0.00       0.0\n",
            "       16482       0.00      0.00      0.00       0.0\n",
            "       16492       0.00      0.00      0.00       0.0\n",
            "       16498       0.00      0.00      0.00       0.0\n",
            "       16500       0.00      0.00      0.00       0.0\n",
            "       16501       0.00      0.00      0.00       0.0\n",
            "       16508       0.00      0.00      0.00       0.0\n",
            "       16509       0.00      0.00      0.00       0.0\n",
            "       16512       0.00      0.00      0.00       0.0\n",
            "       16513       0.00      0.00      0.00       0.0\n",
            "       16514       0.00      0.00      0.00       0.0\n",
            "       16517       0.00      0.00      0.00       0.0\n",
            "       16519       0.00      0.00      0.00       0.0\n",
            "       16523       0.00      0.00      0.00       0.0\n",
            "       16526       0.00      0.00      0.00       0.0\n",
            "       16532       0.00      0.00      0.00       0.0\n",
            "       16534       0.00      0.00      0.00       0.0\n",
            "       16536       0.00      0.00      0.00       0.0\n",
            "       16537       0.00      0.00      0.00       0.0\n",
            "       16544       0.00      0.00      0.00       0.0\n",
            "       16545       0.00      0.00      0.00       0.0\n",
            "       16546       0.00      0.00      0.00       0.0\n",
            "       16550       0.00      0.00      0.00       0.0\n",
            "       16552       0.00      0.00      0.00       0.0\n",
            "       16553       0.00      0.00      0.00       0.0\n",
            "       16561       0.00      0.00      0.00       0.0\n",
            "       16563       0.00      0.00      0.00       0.0\n",
            "       16564       0.00      0.00      0.00       0.0\n",
            "       16565       0.00      0.00      0.00       0.0\n",
            "       16566       0.00      0.00      0.00       0.0\n",
            "       16568       0.00      0.00      0.00       0.0\n",
            "       16570       0.00      0.00      0.00       0.0\n",
            "       16574       0.00      0.00      0.00       0.0\n",
            "       16575       0.00      0.00      0.00       0.0\n",
            "       16576       0.00      0.00      0.00       0.0\n",
            "       16578       0.00      0.00      0.00       0.0\n",
            "       16580       0.00      0.00      0.00       0.0\n",
            "       16581       0.00      0.00      0.00       0.0\n",
            "       16584       0.00      0.00      0.00       0.0\n",
            "       16585       0.00      0.00      0.00       0.0\n",
            "       16588       0.00      0.00      0.00       0.0\n",
            "       16592       0.00      0.00      0.00       0.0\n",
            "       16594       0.00      0.00      0.00       0.0\n",
            "       16596       0.00      0.00      0.00       0.0\n",
            "       16597       0.00      0.00      0.00       0.0\n",
            "       16598       0.00      0.00      0.00       0.0\n",
            "       16600       0.00      0.00      0.00       0.0\n",
            "       16604       0.00      0.00      0.00       0.0\n",
            "       16610       0.00      0.00      0.00       0.0\n",
            "       16614       0.00      0.00      0.00       0.0\n",
            "       16615       0.00      0.00      0.00       0.0\n",
            "       16617       0.00      0.00      0.00       0.0\n",
            "       16620       0.00      0.00      0.00       0.0\n",
            "       16623       0.00      0.00      0.00       0.0\n",
            "       16624       0.00      0.00      0.00       0.0\n",
            "       16625       0.00      0.00      0.00       0.0\n",
            "       16627       0.00      0.00      0.00       0.0\n",
            "       16628       0.00      0.00      0.00       0.0\n",
            "       16630       0.00      0.00      0.00       0.0\n",
            "       16632       0.00      0.00      0.00       0.0\n",
            "       16633       0.00      0.00      0.00       0.0\n",
            "       16636       0.00      0.00      0.00       0.0\n",
            "       16640       0.00      0.00      0.00       0.0\n",
            "       16647       0.00      0.00      0.00       0.0\n",
            "       16648       0.00      0.00      0.00       0.0\n",
            "       16651       0.00      0.00      0.00       0.0\n",
            "       16653       0.00      0.00      0.00       0.0\n",
            "       16655       0.00      0.00      0.00       0.0\n",
            "       16656       0.00      0.00      0.00       0.0\n",
            "       16658       0.00      0.00      0.00       0.0\n",
            "       16659       0.00      0.00      0.00       0.0\n",
            "       16661       0.00      0.00      0.00       0.0\n",
            "       16676       0.00      0.00      0.00       0.0\n",
            "       16677       0.00      0.00      0.00       0.0\n",
            "       16678       0.00      0.00      0.00       0.0\n",
            "       16684       0.00      0.00      0.00       0.0\n",
            "       16686       0.00      0.00      0.00       0.0\n",
            "       16689       0.00      0.00      0.00       0.0\n",
            "       16690       0.00      0.00      0.00       0.0\n",
            "       16691       0.00      0.00      0.00       0.0\n",
            "       16692       0.00      0.00      0.00       0.0\n",
            "       16695       0.00      0.00      0.00       0.0\n",
            "       16698       0.00      0.00      0.00       0.0\n",
            "       16700       0.00      0.00      0.00       0.0\n",
            "       16702       0.00      0.00      0.00       0.0\n",
            "       16704       0.00      0.00      0.00       0.0\n",
            "       16705       0.00      0.00      0.00       0.0\n",
            "       16706       0.00      0.00      0.00       0.0\n",
            "       16712       0.00      0.00      0.00       0.0\n",
            "       16714       0.00      0.00      0.00       0.0\n",
            "       16715       0.00      0.00      0.00       0.0\n",
            "       16716       0.00      0.00      0.00       0.0\n",
            "       16719       0.00      0.00      0.00       0.0\n",
            "       16721       0.00      0.00      0.00       0.0\n",
            "       16723       0.00      0.00      0.00       0.0\n",
            "       16724       0.00      0.00      0.00       0.0\n",
            "       16727       0.00      0.00      0.00       0.0\n",
            "       16729       0.00      0.00      0.00       0.0\n",
            "       16730       0.00      0.00      0.00       0.0\n",
            "       16732       0.00      0.00      0.00       0.0\n",
            "       16735       0.00      0.00      0.00       0.0\n",
            "       16736       0.00      0.00      0.00       0.0\n",
            "       16738       0.00      0.00      0.00       0.0\n",
            "       16739       0.00      0.00      0.00       0.0\n",
            "       16740       0.00      0.00      0.00       0.0\n",
            "       16742       0.00      0.00      0.00       0.0\n",
            "       16746       0.00      0.00      0.00       0.0\n",
            "       16752       0.00      0.00      0.00       0.0\n",
            "       16756       0.00      0.00      0.00       0.0\n",
            "       16757       0.00      0.00      0.00       0.0\n",
            "       16758       0.00      0.00      0.00       0.0\n",
            "       16760       0.00      0.00      0.00       0.0\n",
            "       16763       0.00      0.00      0.00       0.0\n",
            "       16769       0.00      0.00      0.00       0.0\n",
            "       16770       0.00      0.00      0.00       0.0\n",
            "       16774       0.00      0.00      0.00       0.0\n",
            "       16775       0.00      0.00      0.00       0.0\n",
            "       16777       0.00      0.00      0.00       0.0\n",
            "       16779       0.00      0.00      0.00       0.0\n",
            "       16782       0.00      0.00      0.00       0.0\n",
            "       16783       0.00      0.00      0.00       0.0\n",
            "       16785       0.00      0.00      0.00       0.0\n",
            "       16786       0.00      0.00      0.00       0.0\n",
            "       16788       0.00      0.00      0.00       0.0\n",
            "       16790       0.00      0.00      0.00       0.0\n",
            "       16791       0.00      0.00      0.00       0.0\n",
            "       16792       0.00      0.00      0.00       0.0\n",
            "       16794       0.00      0.00      0.00       0.0\n",
            "       16799       0.00      0.00      0.00       0.0\n",
            "       16800       0.00      0.00      0.00       0.0\n",
            "       16804       0.00      0.00      0.00       0.0\n",
            "       16807       0.00      0.00      0.00       0.0\n",
            "       16808       0.00      0.00      0.00       0.0\n",
            "       16811       0.00      0.00      0.00       0.0\n",
            "       16812       0.00      0.00      0.00       0.0\n",
            "       16815       0.00      0.00      0.00       0.0\n",
            "       16816       0.00      0.00      0.00       0.0\n",
            "       16817       0.00      0.00      0.00       0.0\n",
            "       16818       0.00      0.00      0.00       0.0\n",
            "       16820       0.00      0.00      0.00       0.0\n",
            "       16821       0.00      0.00      0.00       0.0\n",
            "       16825       0.00      0.00      0.00       0.0\n",
            "       16826       0.00      0.00      0.00       0.0\n",
            "       16828       0.00      0.00      0.00       0.0\n",
            "       16829       0.00      0.00      0.00       0.0\n",
            "       16831       0.00      0.00      0.00       0.0\n",
            "       16836       0.00      0.00      0.00       0.0\n",
            "       16837       0.00      0.00      0.00       0.0\n",
            "       16840       0.00      0.00      0.00       0.0\n",
            "       16843       0.00      0.00      0.00       0.0\n",
            "       16844       0.00      0.00      0.00       0.0\n",
            "       16846       0.00      0.00      0.00       0.0\n",
            "       16848       0.00      0.00      0.00       0.0\n",
            "       16849       0.00      0.00      0.00       0.0\n",
            "       16853       0.00      0.00      0.00       0.0\n",
            "       16856       0.00      0.00      0.00       0.0\n",
            "       16860       0.00      0.00      0.00       0.0\n",
            "       16862       0.00      0.00      0.00       0.0\n",
            "       16863       0.00      0.00      0.00       0.0\n",
            "       16864       0.00      0.00      0.00       0.0\n",
            "       16865       0.00      0.00      0.00       0.0\n",
            "       16866       0.00      0.00      0.00       0.0\n",
            "       16867       0.00      0.00      0.00       0.0\n",
            "       16868       0.00      0.00      0.00       0.0\n",
            "       16869       0.00      0.00      0.00       0.0\n",
            "       16870       0.00      0.00      0.00       0.0\n",
            "       16871       0.00      0.00      0.00       0.0\n",
            "       16872       0.00      0.00      0.00       0.0\n",
            "       16874       0.00      0.00      0.00       0.0\n",
            "       16876       0.00      0.00      0.00       0.0\n",
            "       16878       0.00      0.00      0.00       0.0\n",
            "       16884       0.00      0.00      0.00       0.0\n",
            "       16885       0.00      0.00      0.00       0.0\n",
            "       16887       0.00      0.00      0.00       0.0\n",
            "       16888       0.00      0.00      0.00       0.0\n",
            "       16896       0.00      0.00      0.00       0.0\n",
            "       16898       0.00      0.00      0.00       0.0\n",
            "       16899       0.00      0.00      0.00       0.0\n",
            "       16902       0.00      0.00      0.00       0.0\n",
            "       16903       0.00      0.00      0.00       0.0\n",
            "       16905       0.00      0.00      0.00       0.0\n",
            "       16907       0.00      0.00      0.00       0.0\n",
            "       16908       0.00      0.00      0.00       0.0\n",
            "       16910       0.00      0.00      0.00       0.0\n",
            "       16912       0.00      0.00      0.00       0.0\n",
            "       16914       0.00      0.00      0.00       0.0\n",
            "       16915       0.00      0.00      0.00       0.0\n",
            "       16916       0.00      0.00      0.00       0.0\n",
            "       16917       0.00      0.00      0.00       0.0\n",
            "       16918       0.00      0.00      0.00       0.0\n",
            "       16919       0.00      0.00      0.00       0.0\n",
            "       16920       0.00      0.00      0.00       0.0\n",
            "       16921       0.00      0.00      0.00       0.0\n",
            "       16922       0.00      0.00      0.00       0.0\n",
            "       16924       0.00      0.00      0.00       0.0\n",
            "       16925       0.00      0.00      0.00       0.0\n",
            "       16926       0.00      0.00      0.00       0.0\n",
            "       16930       0.00      0.00      0.00       0.0\n",
            "       16931       0.00      0.00      0.00       0.0\n",
            "       16932       0.00      0.00      0.00       0.0\n",
            "       16934       0.00      0.00      0.00       0.0\n",
            "       16936       0.00      0.00      0.00       0.0\n",
            "       16940       0.00      0.00      0.00       0.0\n",
            "       16941       0.00      0.00      0.00       0.0\n",
            "       16943       0.00      0.00      0.00       0.0\n",
            "       16944       0.00      0.00      0.00       0.0\n",
            "       16946       0.00      0.00      0.00       0.0\n",
            "       16949       0.00      0.00      0.00       0.0\n",
            "       16951       0.00      0.00      0.00       0.0\n",
            "       16952       0.00      0.00      0.00       0.0\n",
            "       16955       0.00      0.00      0.00       0.0\n",
            "       16956       0.00      0.00      0.00       0.0\n",
            "       16957       0.00      0.00      0.00       0.0\n",
            "       16958       0.00      0.00      0.00       0.0\n",
            "       16959       0.00      0.00      0.00       0.0\n",
            "       16960       0.00      0.00      0.00       0.0\n",
            "       16961       0.00      0.00      0.00       0.0\n",
            "       16963       0.00      0.00      0.00       0.0\n",
            "       16965       0.00      0.00      0.00       0.0\n",
            "       16966       0.00      0.00      0.00       0.0\n",
            "       16968       0.00      0.00      0.00       0.0\n",
            "       16970       0.00      0.00      0.00       0.0\n",
            "       16971       0.00      0.00      0.00       0.0\n",
            "       16972       0.00      0.00      0.00       0.0\n",
            "       16973       0.00      0.00      0.00       0.0\n",
            "       16974       0.00      0.00      0.00       0.0\n",
            "       16976       0.00      0.00      0.00       0.0\n",
            "       16977       0.00      0.00      0.00       0.0\n",
            "       16978       0.00      0.00      0.00       0.0\n",
            "       16981       0.00      0.00      0.00       0.0\n",
            "       16983       0.00      0.00      0.00       0.0\n",
            "       16984       0.00      0.00      0.00       0.0\n",
            "       16986       0.00      0.00      0.00       0.0\n",
            "       16988       0.00      0.00      0.00       0.0\n",
            "       16990       0.00      0.00      0.00       0.0\n",
            "       16991       0.00      0.00      0.00       0.0\n",
            "       16993       0.00      0.00      0.00       0.0\n",
            "       16998       0.00      0.00      0.00       0.0\n",
            "       17002       0.00      0.00      0.00       0.0\n",
            "       17003       0.00      0.00      0.00       0.0\n",
            "       17005       0.00      0.00      0.00       0.0\n",
            "       17008       0.00      0.00      0.00       0.0\n",
            "       17009       0.00      0.00      0.00       0.0\n",
            "       17012       0.00      0.00      0.00       0.0\n",
            "       17013       0.00      0.00      0.00       0.0\n",
            "       17014       0.00      0.00      0.00       0.0\n",
            "       17015       0.00      0.00      0.00       0.0\n",
            "       17016       0.00      0.00      0.00       0.0\n",
            "       17017       0.00      0.00      0.00       0.0\n",
            "       17022       0.00      0.00      0.00       0.0\n",
            "       17023       0.00      0.00      0.00       0.0\n",
            "       17024       0.00      0.00      0.00       0.0\n",
            "       17029       0.00      0.00      0.00       0.0\n",
            "       17030       0.00      0.00      0.00       0.0\n",
            "       17034       0.00      0.00      0.00       0.0\n",
            "       17036       0.00      0.00      0.00       0.0\n",
            "       17037       0.00      0.00      0.00       0.0\n",
            "       17041       0.00      0.00      0.00       0.0\n",
            "       17042       0.00      0.00      0.00       0.0\n",
            "       17043       0.00      0.00      0.00       0.0\n",
            "       17044       0.00      0.00      0.00       0.0\n",
            "       17045       0.00      0.00      0.00       0.0\n",
            "       17046       0.00      0.00      0.00       0.0\n",
            "       17049       0.00      0.00      0.00       0.0\n",
            "       17054       0.00      0.00      0.00       0.0\n",
            "       17055       0.00      0.00      0.00       0.0\n",
            "       17059       0.00      0.00      0.00       0.0\n",
            "       17061       0.00      0.00      0.00       0.0\n",
            "       17062       0.00      0.00      0.00       0.0\n",
            "       17063       0.00      0.00      0.00       0.0\n",
            "       17064       0.00      0.00      0.00       0.0\n",
            "       17066       0.00      0.00      0.00       0.0\n",
            "       17070       0.00      0.00      0.00       0.0\n",
            "       17071       0.00      0.00      0.00       0.0\n",
            "       17072       0.00      0.00      0.00       0.0\n",
            "       17073       0.00      0.00      0.00       0.0\n",
            "       17075       0.00      0.00      0.00       0.0\n",
            "       17076       0.00      0.00      0.00       0.0\n",
            "       17078       0.00      0.00      0.00       0.0\n",
            "       17079       0.00      0.00      0.00       0.0\n",
            "       17081       0.00      0.00      0.00       0.0\n",
            "       17082       0.00      0.00      0.00       0.0\n",
            "       17083       0.00      0.00      0.00       0.0\n",
            "       17084       0.00      0.00      0.00       0.0\n",
            "       17085       0.00      0.00      0.00       0.0\n",
            "       17086       0.00      0.00      0.00       0.0\n",
            "       17087       0.00      0.00      0.00       0.0\n",
            "       17089       0.00      0.00      0.00       0.0\n",
            "       17090       0.00      0.00      0.00       0.0\n",
            "       17091       0.00      0.00      0.00       0.0\n",
            "       17093       0.00      0.00      0.00       0.0\n",
            "       17096       0.00      0.00      0.00       0.0\n",
            "       17097       0.00      0.00      0.00       0.0\n",
            "       17099       0.00      0.00      0.00       0.0\n",
            "       17100       0.00      0.00      0.00       0.0\n",
            "       17102       0.00      0.00      0.00       0.0\n",
            "       17103       0.00      0.00      0.00       0.0\n",
            "       17104       0.00      0.00      0.00       0.0\n",
            "       17105       0.00      0.00      0.00       0.0\n",
            "       17107       0.00      0.00      0.00       0.0\n",
            "       17108       0.00      0.00      0.00       0.0\n",
            "       17109       0.00      0.00      0.00       0.0\n",
            "       17110       0.00      0.00      0.00       0.0\n",
            "       17111       0.00      0.00      0.00       0.0\n",
            "       17112       0.00      0.00      0.00       0.0\n",
            "       17113       0.00      0.00      0.00       0.0\n",
            "       17114       0.00      0.00      0.00       0.0\n",
            "       17115       0.00      0.00      0.00       0.0\n",
            "       17116       0.00      0.00      0.00       0.0\n",
            "       17118       0.00      0.00      0.00       0.0\n",
            "       17119       0.00      0.00      0.00       0.0\n",
            "       17122       0.00      0.00      0.00       0.0\n",
            "       17123       0.00      0.00      0.00       0.0\n",
            "       17124       0.00      0.00      0.00       0.0\n",
            "       17125       0.00      0.00      0.00       0.0\n",
            "       17126       0.00      0.00      0.00       0.0\n",
            "       17127       0.00      0.00      0.00       0.0\n",
            "       17128       0.00      0.00      0.00       0.0\n",
            "       17129       0.00      0.00      0.00       0.0\n",
            "       17130       0.00      0.00      0.00       0.0\n",
            "       17131       0.00      0.00      0.00       0.0\n",
            "       17133       0.00      0.00      0.00       0.0\n",
            "       17134       0.00      0.00      0.00       0.0\n",
            "       17135       0.00      0.00      0.00       0.0\n",
            "       17136       0.00      0.00      0.00       0.0\n",
            "       17137       0.00      0.00      0.00       0.0\n",
            "       17138       0.00      0.00      0.00       0.0\n",
            "       17139       0.00      0.00      0.00       0.0\n",
            "       17140       0.00      0.00      0.00       0.0\n",
            "       17143       0.00      0.00      0.00       0.0\n",
            "       17144       0.00      0.00      0.00       0.0\n",
            "       17145       0.00      0.00      0.00       0.0\n",
            "       17146       0.00      0.00      0.00       0.0\n",
            "       17147       0.00      0.00      0.00       0.0\n",
            "       17148       0.00      0.00      0.00       0.0\n",
            "       17149       0.00      0.00      0.00       0.0\n",
            "       17150       0.00      0.00      0.00       0.0\n",
            "       17151       0.00      0.00      0.00       0.0\n",
            "       17153       0.00      0.00      0.00       0.0\n",
            "       17154       0.00      0.00      0.00       0.0\n",
            "       17156       0.00      0.00      0.00       0.0\n",
            "       17157       0.00      0.00      0.00       0.0\n",
            "       17158       0.00      0.00      0.00       0.0\n",
            "       17160       0.00      0.00      0.00       0.0\n",
            "       17161       0.00      0.00      0.00       0.0\n",
            "       17162       0.00      0.00      0.00       0.0\n",
            "       17163       0.00      0.00      0.00       0.0\n",
            "       17164       0.00      0.00      0.00       0.0\n",
            "       17166       0.00      0.00      0.00       0.0\n",
            "       17169       0.00      0.00      0.00       0.0\n",
            "       17171       0.00      0.00      0.00       0.0\n",
            "       17172       0.00      0.00      0.00       0.0\n",
            "       17173       0.00      0.00      0.00       0.0\n",
            "       17176       0.00      0.00      0.00       0.0\n",
            "       17177       0.00      0.00      0.00       0.0\n",
            "       17179       0.00      0.00      0.00       0.0\n",
            "       17183       0.00      0.00      0.00       0.0\n",
            "       17184       0.00      0.00      0.00       0.0\n",
            "       17185       0.00      0.00      0.00       0.0\n",
            "       17186       0.00      0.00      0.00       0.0\n",
            "       17187       0.00      0.00      0.00       0.0\n",
            "       17188       0.00      0.00      0.00       0.0\n",
            "       17189       0.00      0.00      0.00       0.0\n",
            "       17191       0.00      0.00      0.00       0.0\n",
            "       17192       0.00      0.00      0.00       0.0\n",
            "       17193       0.00      0.00      0.00       0.0\n",
            "       17196       0.00      0.00      0.00       0.0\n",
            "       17197       0.00      0.00      0.00       0.0\n",
            "       17198       0.00      0.00      0.00       0.0\n",
            "       17199       0.00      0.00      0.00       0.0\n",
            "       17201       0.00      0.00      0.00       0.0\n",
            "       17202       0.00      0.00      0.00       0.0\n",
            "       17204       0.00      0.00      0.00       0.0\n",
            "       17205       0.00      0.00      0.00       0.0\n",
            "       17206       0.00      0.00      0.00       0.0\n",
            "       17208       0.00      0.00      0.00       0.0\n",
            "       17209       0.00      0.00      0.00       0.0\n",
            "       17210       0.00      0.00      0.00       0.0\n",
            "       17211       0.00      0.00      0.00       0.0\n",
            "       17212       0.00      0.00      0.00       0.0\n",
            "       17214       0.00      0.00      0.00       0.0\n",
            "       17215       0.00      0.00      0.00       0.0\n",
            "       17217       0.00      0.00      0.00       0.0\n",
            "       17219       0.00      0.00      0.00       0.0\n",
            "       17221       0.00      0.00      0.00       0.0\n",
            "       17222       0.00      0.00      0.00       0.0\n",
            "       17223       0.00      0.00      0.00       0.0\n",
            "       17226       0.00      0.00      0.00       0.0\n",
            "       17227       0.00      0.00      0.00       0.0\n",
            "       17228       0.00      0.00      0.00       0.0\n",
            "       17230       0.00      0.00      0.00       0.0\n",
            "       17231       0.00      0.00      0.00       0.0\n",
            "       17232       0.00      0.00      0.00       0.0\n",
            "       17233       0.00      0.00      0.00       0.0\n",
            "       17234       0.00      0.00      0.00       0.0\n",
            "       17238       0.00      0.00      0.00       0.0\n",
            "       17239       0.00      0.00      0.00       0.0\n",
            "       17240       0.00      0.00      0.00       0.0\n",
            "       17241       0.00      0.00      0.00       0.0\n",
            "       17244       0.00      0.00      0.00       0.0\n",
            "       17245       0.00      0.00      0.00       0.0\n",
            "       17246       0.00      0.00      0.00       0.0\n",
            "       17247       0.00      0.00      0.00       0.0\n",
            "       17248       0.00      0.00      0.00       0.0\n",
            "       17249       0.00      0.00      0.00       0.0\n",
            "       17250       0.00      0.00      0.00       0.0\n",
            "       17251       0.00      0.00      0.00       0.0\n",
            "       17252       0.00      0.00      0.00       0.0\n",
            "       17253       0.00      0.00      0.00       0.0\n",
            "       17256       0.00      0.00      0.00       0.0\n",
            "       17257       0.00      0.00      0.00       0.0\n",
            "       17259       0.00      0.00      0.00       0.0\n",
            "       17261       0.00      0.00      0.00       0.0\n",
            "       17263       0.00      0.00      0.00       0.0\n",
            "       17265       0.00      0.00      0.00       0.0\n",
            "       17266       0.00      0.00      0.00       0.0\n",
            "       17267       0.00      0.00      0.00       0.0\n",
            "       17268       0.00      0.00      0.00       0.0\n",
            "       17269       0.00      0.00      0.00       0.0\n",
            "       17270       0.00      0.00      0.00       0.0\n",
            "       17271       0.00      0.00      0.00       0.0\n",
            "       17272       0.00      0.00      0.00       0.0\n",
            "       17273       0.00      0.00      0.00       0.0\n",
            "       17274       0.00      0.00      0.00       0.0\n",
            "       17276       0.00      0.00      0.00       0.0\n",
            "       17277       0.00      0.00      0.00       0.0\n",
            "       17279       0.00      0.00      0.00       0.0\n",
            "       17280       0.00      0.00      0.00       0.0\n",
            "       17281       0.00      0.00      0.00       0.0\n",
            "       17283       0.00      0.00      0.00       0.0\n",
            "       17284       0.00      0.00      0.00       0.0\n",
            "       17285       0.00      0.00      0.00       0.0\n",
            "       17288       0.00      0.00      0.00       0.0\n",
            "       17289       0.00      0.00      0.00       0.0\n",
            "       17290       0.00      0.00      0.00       0.0\n",
            "       17291       0.00      0.00      0.00       0.0\n",
            "       17292       0.00      0.00      0.00       0.0\n",
            "       17293       0.00      0.00      0.00       0.0\n",
            "       17294       0.00      0.00      0.00       0.0\n",
            "       17295       0.00      0.00      0.00       0.0\n",
            "       17296       0.00      0.00      0.00       0.0\n",
            "       17297       0.00      0.00      0.00       0.0\n",
            "       17298       0.00      0.00      0.00       0.0\n",
            "       17300       0.00      0.00      0.00       0.0\n",
            "       17301       0.00      0.00      0.00       0.0\n",
            "       17302       0.00      0.00      0.00       0.0\n",
            "       17303       0.00      0.00      0.00       0.0\n",
            "       17304       0.00      0.00      0.00       0.0\n",
            "       17305       0.00      0.00      0.00       0.0\n",
            "       17306       0.00      0.00      0.00       0.0\n",
            "       17307       0.00      0.00      0.00       0.0\n",
            "       17308       0.00      0.00      0.00       0.0\n",
            "       17309       0.00      0.00      0.00       0.0\n",
            "       17310       0.00      0.00      0.00       0.0\n",
            "       17311       0.00      0.00      0.00       0.0\n",
            "       17312       0.00      0.00      0.00       0.0\n",
            "       17313       0.00      0.00      0.00       0.0\n",
            "       17314       0.00      0.00      0.00       0.0\n",
            "       17315       0.00      0.00      0.00       0.0\n",
            "       17316       0.00      0.00      0.00       0.0\n",
            "       17317       0.00      0.00      0.00       0.0\n",
            "       17318       0.00      0.00      0.00       0.0\n",
            "       17321       0.00      0.00      0.00       0.0\n",
            "       17322       0.00      0.00      0.00       0.0\n",
            "       17324       0.00      0.00      0.00       0.0\n",
            "       17325       0.00      0.00      0.00       0.0\n",
            "       17326       0.00      0.00      0.00       0.0\n",
            "       17327       0.00      0.00      0.00       0.0\n",
            "       17328       0.00      0.00      0.00       0.0\n",
            "       17332       0.00      0.00      0.00       0.0\n",
            "       17333       0.00      0.00      0.00       0.0\n",
            "       17334       0.00      0.00      0.00       0.0\n",
            "       17336       0.00      0.00      0.00       0.0\n",
            "       17337       0.00      0.00      0.00       0.0\n",
            "       17338       0.00      0.00      0.00       0.0\n",
            "       17339       0.00      0.00      0.00       0.0\n",
            "       17340       0.00      0.00      0.00       0.0\n",
            "       17341       0.00      0.00      0.00       0.0\n",
            "       17342       0.00      0.00      0.00       0.0\n",
            "       17343       0.00      0.00      0.00       0.0\n",
            "       17344       0.00      0.00      0.00       0.0\n",
            "       17346       0.00      0.00      0.00       0.0\n",
            "       17347       0.00      0.00      0.00       0.0\n",
            "       17349       0.00      0.00      0.00       0.0\n",
            "       17350       0.00      0.00      0.00       0.0\n",
            "       17351       0.00      0.00      0.00       0.0\n",
            "       17352       0.00      0.00      0.00       0.0\n",
            "       17356       0.00      0.00      0.00       0.0\n",
            "       17358       0.00      0.00      0.00       0.0\n",
            "       17359       0.00      0.00      0.00       0.0\n",
            "       17361       0.00      0.00      0.00       0.0\n",
            "       17362       0.00      0.00      0.00       0.0\n",
            "       17363       0.00      0.00      0.00       0.0\n",
            "       17364       0.00      0.00      0.00       0.0\n",
            "       17365       0.00      0.00      0.00       0.0\n",
            "       17366       0.00      0.00      0.00       0.0\n",
            "       17368       0.00      0.00      0.00       0.0\n",
            "       17369       0.00      0.00      0.00       0.0\n",
            "       17370       0.00      0.00      0.00       0.0\n",
            "       17372       0.00      0.00      0.00       0.0\n",
            "       17373       0.00      0.00      0.00       0.0\n",
            "       17374       0.00      0.00      0.00       0.0\n",
            "       17375       0.00      0.00      0.00       0.0\n",
            "       17378       0.00      0.00      0.00       0.0\n",
            "       17379       0.00      0.00      0.00       0.0\n",
            "       17381       0.00      0.00      0.00       0.0\n",
            "       17382       0.00      0.00      0.00       0.0\n",
            "       17383       0.00      0.00      0.00       0.0\n",
            "       17384       0.00      0.00      0.00       0.0\n",
            "       17385       0.00      0.00      0.00       0.0\n",
            "       17386       0.00      0.00      0.00       0.0\n",
            "       17387       0.00      0.00      0.00       0.0\n",
            "       17388       0.00      0.00      0.00       0.0\n",
            "       17389       0.00      0.00      0.00       0.0\n",
            "       17390       0.00      0.00      0.00       0.0\n",
            "       17391       0.00      0.00      0.00       0.0\n",
            "       17392       0.00      0.00      0.00       0.0\n",
            "       17393       0.00      0.00      0.00       0.0\n",
            "       17394       0.00      0.00      0.00       0.0\n",
            "       17396       0.00      0.00      0.00       0.0\n",
            "       17397       0.00      0.00      0.00       0.0\n",
            "       17399       0.00      0.00      0.00       0.0\n",
            "       17400       0.00      0.00      0.00       0.0\n",
            "       17401       0.00      0.00      0.00       0.0\n",
            "       17402       0.00      0.00      0.00       0.0\n",
            "       17403       0.00      0.00      0.00       0.0\n",
            "       17404       0.00      0.00      0.00       0.0\n",
            "       17405       0.00      0.00      0.00       0.0\n",
            "       17406       0.00      0.00      0.00       0.0\n",
            "       17407       0.00      0.00      0.00       0.0\n",
            "       17409       0.00      0.00      0.00       0.0\n",
            "       17410       0.00      0.00      0.00       0.0\n",
            "       17411       0.00      0.00      0.00       0.0\n",
            "       17412       0.00      0.00      0.00       0.0\n",
            "       17413       0.00      0.00      0.00       0.0\n",
            "       17414       0.00      0.00      0.00       0.0\n",
            "       17417       0.00      0.00      0.00       0.0\n",
            "       17418       0.00      0.00      0.00       0.0\n",
            "       17419       0.00      0.00      0.00       0.0\n",
            "       17420       0.00      0.00      0.00       0.0\n",
            "       17421       0.00      0.00      0.00       0.0\n",
            "       17423       0.00      0.00      0.00       0.0\n",
            "       17424       0.00      0.00      0.00       0.0\n",
            "       17425       0.00      0.00      0.00       0.0\n",
            "       17426       0.00      0.00      0.00       0.0\n",
            "       17427       0.00      0.00      0.00       0.0\n",
            "       17429       0.00      0.00      0.00       0.0\n",
            "       17430       0.00      0.00      0.00       0.0\n",
            "       17431       0.00      0.00      0.00       0.0\n",
            "       17432       0.00      0.00      0.00       0.0\n",
            "       17433       0.00      0.00      0.00       0.0\n",
            "       17434       0.00      0.00      0.00       0.0\n",
            "       17435       0.00      0.00      0.00       0.0\n",
            "       17436       0.00      0.00      0.00       0.0\n",
            "       17437       0.00      0.00      0.00       0.0\n",
            "       17438       0.00      0.00      0.00       0.0\n",
            "       17440       0.00      0.00      0.00       0.0\n",
            "       17441       0.00      0.00      0.00       0.0\n",
            "       17442       0.00      0.00      0.00       0.0\n",
            "       17443       0.00      0.00      0.00       0.0\n",
            "       17444       0.00      0.00      0.00       0.0\n",
            "       17445       0.00      0.00      0.00       0.0\n",
            "       17446       0.00      0.00      0.00       0.0\n",
            "       17447       0.00      0.00      0.00       0.0\n",
            "       17448       0.00      0.00      0.00       0.0\n",
            "       17449       0.00      0.00      0.00       0.0\n",
            "       17450       0.00      0.00      0.00       0.0\n",
            "       17451       0.00      0.00      0.00       0.0\n",
            "       17452       0.00      0.00      0.00       0.0\n",
            "       17453       0.00      0.00      0.00       0.0\n",
            "       17454       0.00      0.00      0.00       0.0\n",
            "       17455       0.00      0.00      0.00       0.0\n",
            "       17456       0.00      0.00      0.00       0.0\n",
            "       17457       0.00      0.00      0.00       0.0\n",
            "       17459       0.00      0.00      0.00       0.0\n",
            "       17460       0.00      0.00      0.00       0.0\n",
            "       17461       0.00      0.00      0.00       0.0\n",
            "       17462       0.00      0.00      0.00       0.0\n",
            "       17463       0.00      0.00      0.00       0.0\n",
            "       17464       0.00      0.00      0.00       0.0\n",
            "       17465       0.00      0.00      0.00       0.0\n",
            "       17466       0.00      0.00      0.00       0.0\n",
            "       17467       0.00      0.00      0.00       0.0\n",
            "       17468       0.00      0.00      0.00       0.0\n",
            "       17469       0.00      0.00      0.00       0.0\n",
            "       17471       0.00      0.00      0.00       0.0\n",
            "       17472       0.00      0.00      0.00       0.0\n",
            "       17473       0.00      0.00      0.00       0.0\n",
            "       17474       0.00      0.00      0.00       0.0\n",
            "       17476       0.00      0.00      0.00       0.0\n",
            "       17477       0.00      0.00      0.00       0.0\n",
            "       17479       0.00      0.00      0.00       0.0\n",
            "       17480       0.00      0.00      0.00       0.0\n",
            "       17481       0.00      0.00      0.00       0.0\n",
            "       17482       0.00      0.00      0.00       0.0\n",
            "       17483       0.00      0.00      0.00       0.0\n",
            "       17484       0.00      0.00      0.00       0.0\n",
            "       17485       0.00      0.00      0.00       0.0\n",
            "       17486       0.00      0.00      0.00       0.0\n",
            "       17487       0.00      0.00      0.00       0.0\n",
            "       17488       0.00      0.00      0.00       0.0\n",
            "       17490       0.00      0.00      0.00       0.0\n",
            "       17491       0.00      0.00      0.00       0.0\n",
            "       17492       0.00      0.00      0.00       0.0\n",
            "       17493       0.00      0.00      0.00       0.0\n",
            "       17496       0.00      0.00      0.00       0.0\n",
            "       17497       0.00      0.00      0.00       0.0\n",
            "       17498       0.00      0.00      0.00       0.0\n",
            "       17499       0.00      0.00      0.00       0.0\n",
            "       17500       0.00      0.00      0.00       0.0\n",
            "       17501       0.00      0.00      0.00       0.0\n",
            "       17502       0.00      0.00      0.00       0.0\n",
            "       17503       0.00      0.00      0.00       0.0\n",
            "       17504       0.00      0.00      0.00       0.0\n",
            "       17506       0.00      0.00      0.00       0.0\n",
            "       17507       0.00      0.00      0.00       0.0\n",
            "       17508       0.00      0.00      0.00       0.0\n",
            "       17509       0.00      0.00      0.00       0.0\n",
            "       17511       0.00      0.00      0.00       0.0\n",
            "       17512       0.00      0.00      0.00       0.0\n",
            "       17513       0.00      0.00      0.00       0.0\n",
            "       17514       0.00      0.00      0.00       0.0\n",
            "       17515       0.00      0.00      0.00       0.0\n",
            "       17516       0.00      0.00      0.00       0.0\n",
            "       17517       0.00      0.00      0.00       0.0\n",
            "       17518       0.00      0.00      0.00       0.0\n",
            "       17519       0.00      0.00      0.00       0.0\n",
            "       17520       0.00      0.00      0.00       0.0\n",
            "       17521       0.00      0.00      0.00       0.0\n",
            "       17523       0.00      0.00      0.00       0.0\n",
            "       17524       0.00      0.00      0.00       0.0\n",
            "       17527       0.00      0.00      0.00       0.0\n",
            "       17528       0.00      0.00      0.00       0.0\n",
            "       17529       0.00      0.00      0.00       0.0\n",
            "       17530       0.00      0.00      0.00       0.0\n",
            "       17531       0.00      0.00      0.00       0.0\n",
            "       17532       0.00      0.00      0.00       0.0\n",
            "       17534       0.00      0.00      0.00       0.0\n",
            "       17535       0.00      0.00      0.00       0.0\n",
            "       17536       0.00      0.00      0.00       0.0\n",
            "       17537       0.00      0.00      0.00       0.0\n",
            "       17538       0.00      0.00      0.00       0.0\n",
            "       17539       0.00      0.00      0.00       0.0\n",
            "       17540       0.00      0.00      0.00       0.0\n",
            "       17541       0.00      0.00      0.00       0.0\n",
            "       17542       0.00      0.00      0.00       0.0\n",
            "       17543       0.00      0.00      0.00       0.0\n",
            "       17544       0.00      0.00      0.00       0.0\n",
            "       17545       0.00      0.00      0.00       0.0\n",
            "       17546       0.00      0.00      0.00       0.0\n",
            "       17549       0.00      0.00      0.00       0.0\n",
            "       17550       0.00      0.00      0.00       0.0\n",
            "       17551       0.00      0.00      0.00       0.0\n",
            "       17552       0.00      0.00      0.00       0.0\n",
            "       17553       0.00      0.00      0.00       0.0\n",
            "       17554       0.00      0.00      0.00       0.0\n",
            "       17555       0.00      0.00      0.00       0.0\n",
            "       17556       0.00      0.00      0.00       0.0\n",
            "       17557       0.00      0.00      0.00       0.0\n",
            "       17558       0.00      0.00      0.00       0.0\n",
            "       17559       0.00      0.00      0.00       0.0\n",
            "       17560       0.00      0.00      0.00       0.0\n",
            "       17562       0.00      0.00      0.00       0.0\n",
            "       17564       0.00      0.00      0.00       0.0\n",
            "       17565       0.00      0.00      0.00       0.0\n",
            "       17566       0.00      0.00      0.00       0.0\n",
            "       17567       0.00      0.00      0.00       0.0\n",
            "       17568       0.00      0.00      0.00       0.0\n",
            "       17569       0.00      0.00      0.00       0.0\n",
            "       17570       0.00      0.00      0.00       0.0\n",
            "       17571       0.00      0.00      0.00       0.0\n",
            "       17572       0.00      0.00      0.00       0.0\n",
            "       17573       0.00      0.00      0.00       0.0\n",
            "       17574       0.00      0.00      0.00       0.0\n",
            "       17575       0.00      0.00      0.00       0.0\n",
            "       17576       0.00      0.00      0.00       0.0\n",
            "       17577       0.00      0.00      0.00       0.0\n",
            "       17579       0.00      0.00      0.00       0.0\n",
            "       17580       0.00      0.00      0.00       0.0\n",
            "       17582       0.00      0.00      0.00       0.0\n",
            "       17583       0.00      0.00      0.00       0.0\n",
            "       17585       0.00      0.00      0.00       0.0\n",
            "       17586       0.00      0.00      0.00       0.0\n",
            "       17587       0.00      0.00      0.00       0.0\n",
            "       17588       0.00      0.00      0.00       0.0\n",
            "       17589       0.00      0.00      0.00       0.0\n",
            "       17590       0.00      0.00      0.00       0.0\n",
            "       17591       0.00      0.00      0.00       0.0\n",
            "       17592       0.00      0.00      0.00       0.0\n",
            "       17593       0.00      0.00      0.00       0.0\n",
            "       17594       0.00      0.00      0.00       0.0\n",
            "       17595       0.00      0.00      0.00       0.0\n",
            "       17596       0.00      0.00      0.00       0.0\n",
            "       17597       0.00      0.00      0.00       0.0\n",
            "       17599       0.00      0.00      0.00       0.0\n",
            "       17600       0.00      0.00      0.00       0.0\n",
            "       17601       0.00      0.00      0.00       0.0\n",
            "       17602       0.00      0.00      0.00       0.0\n",
            "       17603       0.00      0.00      0.00       0.0\n",
            "       17604       0.00      0.00      0.00       0.0\n",
            "       17605       0.00      0.00      0.00       0.0\n",
            "       17606       0.00      0.00      0.00       0.0\n",
            "       17607       0.00      0.00      0.00       0.0\n",
            "       17608       0.00      0.00      0.00       0.0\n",
            "       17609       0.00      0.00      0.00       0.0\n",
            "       17610       0.00      0.00      0.00       0.0\n",
            "       17611       0.00      0.00      0.00       0.0\n",
            "       17612       0.00      0.00      0.00       0.0\n",
            "       17613       0.00      0.00      0.00       0.0\n",
            "       17614       0.00      0.00      0.00       0.0\n",
            "       17615       0.00      0.00      0.00       0.0\n",
            "       17617       0.00      0.00      0.00       0.0\n",
            "       17618       0.00      0.00      0.00       0.0\n",
            "       17619       0.00      0.00      0.00       0.0\n",
            "       17620       0.00      0.00      0.00       0.0\n",
            "       17621       0.00      0.00      0.00       0.0\n",
            "       17622       0.00      0.00      0.00       0.0\n",
            "       17623       0.00      0.00      0.00       0.0\n",
            "       17624       0.00      0.00      0.00       0.0\n",
            "       17626       0.00      0.00      0.00       0.0\n",
            "       17627       0.00      0.00      0.00       0.0\n",
            "       17628       0.00      0.00      0.00       0.0\n",
            "       17629       0.00      0.00      0.00       0.0\n",
            "       17630       0.00      0.00      0.00       0.0\n",
            "       17631       0.00      0.00      0.00       0.0\n",
            "       17632       0.00      0.00      0.00       0.0\n",
            "       17633       0.00      0.00      0.00       0.0\n",
            "       17634       0.00      0.00      0.00       0.0\n",
            "       17635       0.00      0.00      0.00       0.0\n",
            "       17636       0.00      0.00      0.00       0.0\n",
            "       17637       0.00      0.00      0.00       0.0\n",
            "       17638       0.00      0.00      0.00       0.0\n",
            "       17639       0.00      0.00      0.00       0.0\n",
            "       17640       0.00      0.00      0.00       0.0\n",
            "       17642       0.00      0.00      0.00       0.0\n",
            "       17643       0.00      0.00      0.00       0.0\n",
            "       17644       0.00      0.00      0.00       0.0\n",
            "       17645       0.00      0.00      0.00       0.0\n",
            "       17646       0.00      0.00      0.00       0.0\n",
            "       17647       0.00      0.00      0.00       0.0\n",
            "       17648       0.00      0.00      0.00       0.0\n",
            "       17649       0.00      0.00      0.00       0.0\n",
            "       17650       0.00      0.00      0.00       0.0\n",
            "       17651       0.00      0.00      0.00       0.0\n",
            "       17653       0.00      0.00      0.00       0.0\n",
            "       17654       0.00      0.00      0.00       0.0\n",
            "       17655       0.00      0.00      0.00       0.0\n",
            "       17656       0.00      0.00      0.00       0.0\n",
            "       17657       0.00      0.00      0.00       0.0\n",
            "       17658       0.00      0.00      0.00       0.0\n",
            "       17659       0.00      0.00      0.00       0.0\n",
            "       17660       0.00      0.00      0.00       0.0\n",
            "       17661       0.00      0.00      0.00       0.0\n",
            "       17663       0.00      0.00      0.00       0.0\n",
            "       17664       0.00      0.00      0.00       0.0\n",
            "       17665       0.00      0.00      0.00       0.0\n",
            "       17666       0.00      0.00      0.00       0.0\n",
            "       17668       0.00      0.00      0.00       0.0\n",
            "       17669       0.00      0.00      0.00       0.0\n",
            "       17670       0.00      0.00      0.00       0.0\n",
            "       17671       0.00      0.00      0.00       0.0\n",
            "       17672       0.00      0.00      0.00       0.0\n",
            "       17673       0.00      0.00      0.00       0.0\n",
            "       17674       0.00      0.00      0.00       0.0\n",
            "       17675       0.00      0.00      0.00       0.0\n",
            "       17676       0.00      0.00      0.00       0.0\n",
            "       17677       0.00      0.00      0.00       0.0\n",
            "       17678       0.00      0.00      0.00       0.0\n",
            "       17679       0.00      0.00      0.00       0.0\n",
            "       17680       0.00      0.00      0.00       0.0\n",
            "       17681       0.00      0.00      0.00       0.0\n",
            "       17682       0.00      0.00      0.00       0.0\n",
            "       17683       0.00      0.00      0.00       0.0\n",
            "       17684       0.00      0.00      0.00       0.0\n",
            "       17685       0.00      0.00      0.00       0.0\n",
            "       17686       0.00      0.00      0.00       0.0\n",
            "       17687       0.00      0.00      0.00       0.0\n",
            "       17688       0.00      0.00      0.00       0.0\n",
            "       17689       0.00      0.00      0.00       0.0\n",
            "       17690       0.00      0.00      0.00       0.0\n",
            "       17691       0.00      0.00      0.00       0.0\n",
            "       17692       0.00      0.00      0.00       0.0\n",
            "       17693       0.00      0.00      0.00       0.0\n",
            "       17694       0.00      0.00      0.00       0.0\n",
            "       17695       0.00      0.00      0.00       0.0\n",
            "       17696       0.00      0.00      0.00       0.0\n",
            "       17697       0.00      0.00      0.00       0.0\n",
            "       17698       0.00      0.00      0.00       0.0\n",
            "       17699       0.00      0.00      0.00       0.0\n",
            "       17700       0.00      0.00      0.00       0.0\n",
            "       17701       0.00      0.00      0.00       0.0\n",
            "       17702       0.00      0.00      0.00       0.0\n",
            "       17703       0.00      0.00      0.00       0.0\n",
            "       17704       0.00      0.00      0.00       0.0\n",
            "       17705       0.00      0.00      0.00       0.0\n",
            "       17706       0.00      0.00      0.00       0.0\n",
            "       17707       0.00      0.00      0.00       0.0\n",
            "       17708       0.00      0.00      0.00       0.0\n",
            "       17709       0.00      0.00      0.00       0.0\n",
            "       17710       0.00      0.00      0.00       0.0\n",
            "       17711       0.00      0.00      0.00       0.0\n",
            "       17712       0.00      0.00      0.00       0.0\n",
            "       17713       0.00      0.00      0.00       0.0\n",
            "       17714       0.00      0.00      0.00       0.0\n",
            "       17715       0.00      0.00      0.00       0.0\n",
            "       17716       0.00      0.00      0.00       0.0\n",
            "       17717       0.00      0.00      0.00       0.0\n",
            "       17719       0.00      0.00      0.00       0.0\n",
            "       17720       0.00      0.00      0.00       0.0\n",
            "       17722       0.00      0.00      0.00       0.0\n",
            "       17723       0.00      0.00      0.00       0.0\n",
            "       17724       0.00      0.00      0.00       0.0\n",
            "       17725       0.00      0.00      0.00       0.0\n",
            "       17726       0.00      0.00      0.00       0.0\n",
            "       17727       0.00      0.00      0.00       0.0\n",
            "       17728       0.00      0.00      0.00       0.0\n",
            "       17729       0.00      0.00      0.00       0.0\n",
            "       17730       0.00      0.00      0.00       0.0\n",
            "       17731       0.00      0.00      0.00       0.0\n",
            "       17733       0.00      0.00      0.00       0.0\n",
            "       17734       0.00      0.00      0.00       0.0\n",
            "       17735       0.00      0.00      0.00       0.0\n",
            "       17736       0.00      0.00      0.00       0.0\n",
            "       17737       0.00      0.00      0.00       0.0\n",
            "       17738       0.00      0.00      0.00       0.0\n",
            "       17739       0.00      0.00      0.00       0.0\n",
            "       17740       0.00      0.00      0.00       0.0\n",
            "       17742       0.00      0.00      0.00       0.0\n",
            "       17743       0.00      0.00      0.00       0.0\n",
            "       17744       0.00      0.00      0.00       0.0\n",
            "       17745       0.00      0.00      0.00       0.0\n",
            "       17746       0.00      0.00      0.00       0.0\n",
            "       17747       0.00      0.00      0.00       0.0\n",
            "       17748       0.00      0.00      0.00       0.0\n",
            "       17749       0.00      0.00      0.00       0.0\n",
            "       17750       0.00      0.00      0.00       0.0\n",
            "       17751       0.00      0.00      0.00       0.0\n",
            "       17752       0.00      0.00      0.00       0.0\n",
            "       17753       0.00      0.00      0.00       0.0\n",
            "       17754       0.00      0.00      0.00       0.0\n",
            "       17755       0.00      0.00      0.00       0.0\n",
            "       17756       0.00      0.00      0.00       0.0\n",
            "       17757       0.00      0.00      0.00       0.0\n",
            "       17758       0.00      0.00      0.00       0.0\n",
            "       17759       0.00      0.00      0.00       0.0\n",
            "       17760       0.00      0.00      0.00       0.0\n",
            "       17761       0.00      0.00      0.00       0.0\n",
            "       17762       0.00      0.00      0.00       0.0\n",
            "       17763       0.00      0.00      0.00       0.0\n",
            "       17765       0.00      0.00      0.00       0.0\n",
            "       17766       0.00      0.00      0.00       0.0\n",
            "       17767       0.00      0.00      0.00       0.0\n",
            "       17768       0.00      0.00      0.00       0.0\n",
            "       17769       0.00      0.00      0.00       0.0\n",
            "       17770       0.00      0.00      0.00       0.0\n",
            "       17771       0.00      0.00      0.00       0.0\n",
            "       17773       0.00      0.00      0.00       0.0\n",
            "       17774       0.00      0.00      0.00       0.0\n",
            "       17775       0.00      0.00      0.00       0.0\n",
            "       17776       0.00      0.00      0.00       0.0\n",
            "       17777       0.00      0.00      0.00       0.0\n",
            "       17778       0.00      0.00      0.00       0.0\n",
            "       17779       0.00      0.00      0.00       0.0\n",
            "       17780       0.00      0.00      0.00       0.0\n",
            "       17781       0.00      0.00      0.00       0.0\n",
            "       17782       0.00      0.00      0.00       0.0\n",
            "       17783       0.00      0.00      0.00       0.0\n",
            "       17784       0.00      0.00      0.00       0.0\n",
            "       17785       0.00      0.00      0.00       0.0\n",
            "       17786       0.00      0.00      0.00       0.0\n",
            "       17787       0.00      0.00      0.00       0.0\n",
            "       17788       0.00      0.00      0.00       0.0\n",
            "       17789       0.00      0.00      0.00       0.0\n",
            "       17790       0.00      0.00      0.00       0.0\n",
            "       17791       0.00      0.00      0.00       0.0\n",
            "       17792       0.00      0.00      0.00       0.0\n",
            "       17793       0.00      0.00      0.00       0.0\n",
            "       17794       0.00      0.00      0.00       0.0\n",
            "       17795       0.00      0.00      0.00       0.0\n",
            "       17797       0.00      0.00      0.00       0.0\n",
            "       17798       0.00      0.00      0.00       0.0\n",
            "       17799       0.00      0.00      0.00       0.0\n",
            "       17800       0.00      0.00      0.00       0.0\n",
            "       17801       0.00      0.00      0.00       0.0\n",
            "       17802       0.00      0.00      0.00       0.0\n",
            "       17803       0.00      0.00      0.00       0.0\n",
            "       17804       0.00      0.00      0.00       0.0\n",
            "       17805       0.00      0.00      0.00       0.0\n",
            "       17806       0.00      0.00      0.00       0.0\n",
            "       17807       0.00      0.00      0.00       0.0\n",
            "       17808       0.00      0.00      0.00       0.0\n",
            "       17809       0.00      0.00      0.00       0.0\n",
            "       17810       0.00      0.00      0.00       0.0\n",
            "       17811       0.00      0.00      0.00       0.0\n",
            "       17812       0.00      0.00      0.00       0.0\n",
            "       17813       0.00      0.00      0.00       0.0\n",
            "       17814       0.00      0.00      0.00       0.0\n",
            "       17815       0.00      0.00      0.00       0.0\n",
            "       17816       0.00      0.00      0.00       0.0\n",
            "       17817       0.00      0.00      0.00       0.0\n",
            "       17818       0.00      0.00      0.00       0.0\n",
            "       17820       0.00      0.00      0.00       0.0\n",
            "       17821       0.00      0.00      0.00       0.0\n",
            "       17822       0.00      0.00      0.00       0.0\n",
            "       17823       0.00      0.00      0.00       0.0\n",
            "       17824       0.00      0.00      0.00       0.0\n",
            "       17825       0.00      0.00      0.00       0.0\n",
            "       17826       0.00      0.00      0.00       0.0\n",
            "       17827       0.00      0.00      0.00       0.0\n",
            "       17828       0.00      0.00      0.00       0.0\n",
            "       17829       0.00      0.00      0.00       0.0\n",
            "       17830       0.00      0.00      0.00       0.0\n",
            "       17831       0.00      0.00      0.00       0.0\n",
            "       17832       0.00      0.00      0.00       0.0\n",
            "       17833       0.00      0.00      0.00       0.0\n",
            "       17834       0.00      0.00      0.00       0.0\n",
            "       17835       0.00      0.00      0.00       0.0\n",
            "       17836       0.00      0.00      0.00       0.0\n",
            "       17837       0.00      0.00      0.00       0.0\n",
            "       17838       0.00      0.00      0.00       0.0\n",
            "       17839       0.00      0.00      0.00       0.0\n",
            "       17840       0.00      0.00      0.00       0.0\n",
            "       17841       0.00      0.00      0.00       0.0\n",
            "       17842       0.00      0.00      0.00       0.0\n",
            "       17843       0.00      0.00      0.00       0.0\n",
            "       17844       0.00      0.00      0.00       0.0\n",
            "       17845       0.00      0.00      0.00       0.0\n",
            "       17846       0.00      0.00      0.00       0.0\n",
            "       17847       0.00      0.00      0.00       0.0\n",
            "       17848       0.00      0.00      0.00       0.0\n",
            "       17849       0.00      0.00      0.00       0.0\n",
            "       17850       0.00      0.00      0.00       0.0\n",
            "       17851       0.00      0.00      0.00       0.0\n",
            "       17852       0.00      0.00      0.00       0.0\n",
            "       17854       0.00      0.00      0.00       0.0\n",
            "       17855       0.00      0.00      0.00       0.0\n",
            "       17856       0.00      0.00      0.00       0.0\n",
            "       17857       0.00      0.00      0.00       0.0\n",
            "       17858       0.00      0.00      0.00       0.0\n",
            "       17859       0.00      0.00      0.00       0.0\n",
            "       17860       0.00      0.00      0.00       0.0\n",
            "       17861       0.00      0.00      0.00       0.0\n",
            "       17862       0.00      0.00      0.00       0.0\n",
            "       17863       0.00      0.00      0.00       0.0\n",
            "       17864       0.00      0.00      0.00       0.0\n",
            "       17865       0.00      0.00      0.00       0.0\n",
            "       17866       0.00      0.00      0.00       0.0\n",
            "       17867       0.00      0.00      0.00       0.0\n",
            "       17868       0.00      0.00      0.00       0.0\n",
            "       17869       0.00      0.00      0.00       0.0\n",
            "       17870       0.00      0.00      0.00       0.0\n",
            "       17871       0.00      0.00      0.00       0.0\n",
            "       17872       0.00      0.00      0.00       0.0\n",
            "       17873       0.00      0.00      0.00       0.0\n",
            "       17874       0.00      0.00      0.00       0.0\n",
            "       17875       0.00      0.00      0.00       0.0\n",
            "       17876       0.00      0.00      0.00       0.0\n",
            "       17877       0.00      0.00      0.00       0.0\n",
            "       17878       0.00      0.00      0.00       0.0\n",
            "       17879       0.00      0.00      0.00       0.0\n",
            "       17880       0.00      0.00      0.00       0.0\n",
            "       17881       0.00      0.00      0.00       0.0\n",
            "       17882       0.00      0.00      0.00       0.0\n",
            "       17883       0.00      0.00      0.00       0.0\n",
            "       17884       0.00      0.00      0.00       0.0\n",
            "       17885       0.00      0.00      0.00       0.0\n",
            "       17886       0.00      0.00      0.00       0.0\n",
            "       17887       0.00      0.00      0.00       0.0\n",
            "       17888       0.00      0.00      0.00       0.0\n",
            "       17889       0.00      0.00      0.00       0.0\n",
            "       17890       0.00      0.00      0.00       0.0\n",
            "       17891       0.00      0.00      0.00       0.0\n",
            "       17892       0.00      0.00      0.00       0.0\n",
            "       17893       0.00      0.00      0.00       0.0\n",
            "       17894       0.00      0.00      0.00       0.0\n",
            "       17895       0.00      0.00      0.00       0.0\n",
            "       17896       0.00      0.00      0.00       0.0\n",
            "       17897       0.00      0.00      0.00       0.0\n",
            "       17898       0.00      0.00      0.00       0.0\n",
            "       17899       0.00      0.00      0.00       0.0\n",
            "       17900       0.00      0.00      0.00       0.0\n",
            "       17901       0.00      0.00      0.00       0.0\n",
            "       17902       0.00      0.00      0.00       0.0\n",
            "       17903       0.00      0.00      0.00       0.0\n",
            "       17904       0.00      0.00      0.00       0.0\n",
            "       17905       0.00      0.00      0.00       0.0\n",
            "       17906       0.00      0.00      0.00       0.0\n",
            "       17907       0.00      0.00      0.00       0.0\n",
            "       17908       0.00      0.00      0.00       0.0\n",
            "       17909       0.00      0.00      0.00       0.0\n",
            "       17910       0.00      0.00      0.00       0.0\n",
            "       17911       0.00      0.00      0.00       0.0\n",
            "       17912       0.00      0.00      0.00       0.0\n",
            "       17913       0.00      0.00      0.00       0.0\n",
            "       17914       0.00      0.00      0.00       0.0\n",
            "       17915       0.00      0.00      0.00       0.0\n",
            "       17916       0.00      0.00      0.00       0.0\n",
            "       17917       0.00      0.00      0.00       0.0\n",
            "       17918       0.00      0.00      0.00       0.0\n",
            "       17919       0.00      0.00      0.00       0.0\n",
            "       17920       0.00      0.00      0.00       0.0\n",
            "       17921       0.00      0.00      0.00       0.0\n",
            "       17922       0.00      0.00      0.00       0.0\n",
            "       17923       0.00      0.00      0.00       0.0\n",
            "       17924       0.00      0.00      0.00       0.0\n",
            "       17925       0.00      0.00      0.00       0.0\n",
            "       17926       0.00      0.00      0.00       0.0\n",
            "       17927       0.00      0.00      0.00       0.0\n",
            "       17928       0.00      0.00      0.00       0.0\n",
            "       17929       0.00      0.00      0.00       0.0\n",
            "       17930       0.00      0.00      0.00       0.0\n",
            "       17931       0.00      0.00      0.00       0.0\n",
            "       17932       0.00      0.00      0.00       0.0\n",
            "       17933       0.00      0.00      0.00       0.0\n",
            "       17934       0.00      0.00      0.00       0.0\n",
            "       17935       0.00      0.00      0.00       0.0\n",
            "       17936       0.00      0.00      0.00       0.0\n",
            "       17937       0.00      0.00      0.00       0.0\n",
            "       17938       0.00      0.00      0.00       0.0\n",
            "       17939       0.00      0.00      0.00       0.0\n",
            "       17940       0.00      0.00      0.00       0.0\n",
            "       17941       0.00      0.00      0.00       0.0\n",
            "       17942       0.00      0.00      0.00       0.0\n",
            "       17943       0.00      0.00      0.00       0.0\n",
            "       17944       0.00      0.00      0.00       0.0\n",
            "       17945       0.00      0.00      0.00       0.0\n",
            "       17946       0.00      0.00      0.00       0.0\n",
            "       17947       0.00      0.00      0.00       0.0\n",
            "       17948       0.00      0.00      0.00       0.0\n",
            "       17949       0.00      0.00      0.00       0.0\n",
            "       17950       0.00      0.00      0.00       0.0\n",
            "       17951       0.00      0.00      0.00       0.0\n",
            "       17952       0.00      0.00      0.00       0.0\n",
            "       17953       0.00      0.00      0.00       0.0\n",
            "       17954       0.00      0.00      0.00       0.0\n",
            "       17955       0.00      0.00      0.00       0.0\n",
            "       17956       0.00      0.00      0.00       0.0\n",
            "       17957       0.00      0.00      0.00       0.0\n",
            "       17958       0.00      0.00      0.00       0.0\n",
            "       17959       0.00      0.00      0.00       0.0\n",
            "       17960       0.00      0.00      0.00       0.0\n",
            "       17961       0.00      0.00      0.00       0.0\n",
            "       17962       0.00      0.00      0.00       0.0\n",
            "       17963       0.00      0.00      0.00       0.0\n",
            "       17964       0.00      0.00      0.00       0.0\n",
            "       17965       0.00      0.00      0.00       0.0\n",
            "       17966       0.00      0.00      0.00       0.0\n",
            "       17967       0.00      0.00      0.00       0.0\n",
            "       17968       0.00      0.00      0.00       0.0\n",
            "       17969       0.00      0.00      0.00       0.0\n",
            "       17970       0.00      0.00      0.00       0.0\n",
            "       17971       0.00      0.00      0.00       0.0\n",
            "       17972       0.00      0.00      0.00       0.0\n",
            "       17973       0.00      0.00      0.00       0.0\n",
            "       17974       0.00      0.00      0.00       0.0\n",
            "       17975       0.00      0.00      0.00       0.0\n",
            "       17976       0.00      0.00      0.00       0.0\n",
            "       17977       0.00      0.00      0.00       0.0\n",
            "       17978       0.00      0.00      0.00       0.0\n",
            "       17979       0.00      0.00      0.00       0.0\n",
            "       17980       0.00      0.00      0.00       0.0\n",
            "       17981       0.00      0.00      0.00       0.0\n",
            "       17982       0.00      0.00      0.00       0.0\n",
            "       17983       0.00      0.00      0.00       0.0\n",
            "       17984       0.00      0.00      0.00       0.0\n",
            "       17985       0.00      0.00      0.00       0.0\n",
            "       17986       0.00      0.00      0.00       0.0\n",
            "       17987       0.00      0.00      0.00       0.0\n",
            "       17988       0.00      0.00      0.00       0.0\n",
            "       17989       0.00      0.00      0.00       0.0\n",
            "       17990       0.00      0.00      0.00       0.0\n",
            "       17991       0.00      0.00      0.00       0.0\n",
            "       17992       0.00      0.00      0.00       0.0\n",
            "       17993       0.00      0.00      0.00       0.0\n",
            "       17994       0.00      0.00      0.00       0.0\n",
            "       17995       0.00      0.00      0.00       0.0\n",
            "       17996       0.00      0.00      0.00       0.0\n",
            "       17997       0.00      0.00      0.00       0.0\n",
            "       17998       0.00      0.00      0.00       0.0\n",
            "       17999       0.00      0.00      0.00       0.0\n",
            "       18000       0.00      0.00      0.00       0.0\n",
            "       18001       0.00      0.00      0.00       0.0\n",
            "       18002       0.00      0.00      0.00       0.0\n",
            "       18003       0.00      0.00      0.00       0.0\n",
            "       18004       0.00      0.00      0.00       0.0\n",
            "       18005       0.00      0.00      0.00       0.0\n",
            "       18006       0.00      0.00      0.00       0.0\n",
            "       18007       0.00      0.00      0.00       0.0\n",
            "       18008       0.00      0.00      0.00       0.0\n",
            "       18009       0.00      0.00      0.00       0.0\n",
            "       18010       0.00      0.00      0.00       0.0\n",
            "       18011       0.00      0.00      0.00       0.0\n",
            "       18012       0.00      0.00      0.00       0.0\n",
            "       18013       0.00      0.00      0.00       0.0\n",
            "       18014       0.00      0.00      0.00       0.0\n",
            "       18015       0.00      0.00      0.00       0.0\n",
            "       18016       0.00      0.00      0.00       0.0\n",
            "       18017       0.00      0.00      0.00       0.0\n",
            "       18018       0.00      0.00      0.00       0.0\n",
            "       18019       0.00      0.00      0.00       0.0\n",
            "       18020       0.00      0.00      0.00       0.0\n",
            "       18021       0.00      0.00      0.00       0.0\n",
            "       18022       0.00      0.00      0.00       0.0\n",
            "       18023       0.00      0.00      0.00       0.0\n",
            "       18024       0.00      0.00      0.00       0.0\n",
            "       18025       0.00      0.00      0.00       0.0\n",
            "       18026       0.00      0.00      0.00       0.0\n",
            "       18027       0.00      0.00      0.00       0.0\n",
            "       18028       0.00      0.00      0.00       0.0\n",
            "       18029       0.00      0.00      0.00       0.0\n",
            "       18030       0.00      0.00      0.00       0.0\n",
            "       18031       0.00      0.00      0.00       0.0\n",
            "       18032       0.00      0.00      0.00       0.0\n",
            "       18033       0.00      0.00      0.00       0.0\n",
            "       18034       0.00      0.00      0.00       0.0\n",
            "       18035       0.00      0.00      0.00       0.0\n",
            "       18036       0.00      0.00      0.00       0.0\n",
            "       18037       0.00      0.00      0.00       0.0\n",
            "       18038       0.00      0.00      0.00       0.0\n",
            "       18039       0.00      0.00      0.00       0.0\n",
            "       18040       0.00      0.00      0.00       0.0\n",
            "       18041       0.00      0.00      0.00       0.0\n",
            "       18042       0.00      0.00      0.00       0.0\n",
            "       18043       0.00      0.00      0.00       0.0\n",
            "       18044       0.00      0.00      0.00       0.0\n",
            "       18045       0.00      0.00      0.00       0.0\n",
            "       18046       0.00      0.00      0.00       0.0\n",
            "       18047       0.00      0.00      0.00       0.0\n",
            "       18048       0.00      0.00      0.00       0.0\n",
            "       18049       0.00      0.00      0.00       0.0\n",
            "       18050       0.00      0.00      0.00       0.0\n",
            "       18051       0.00      0.00      0.00       0.0\n",
            "       18052       0.00      0.00      0.00       0.0\n",
            "       18053       0.00      0.00      0.00       0.0\n",
            "       18054       0.00      0.00      0.00       0.0\n",
            "       18055       0.00      0.00      0.00       0.0\n",
            "       18056       0.00      0.00      0.00       0.0\n",
            "       18057       0.00      0.00      0.00       0.0\n",
            "       18058       0.00      0.00      0.00       0.0\n",
            "       18059       0.00      0.00      0.00       0.0\n",
            "       18060       0.00      0.00      0.00       0.0\n",
            "       18061       0.00      0.00      0.00       0.0\n",
            "       18062       0.00      0.00      0.00       0.0\n",
            "       18063       0.00      0.00      0.00       0.0\n",
            "       18064       0.00      0.00      0.00       0.0\n",
            "       18065       0.00      0.00      0.00       0.0\n",
            "       18066       0.00      0.00      0.00       0.0\n",
            "       18067       0.00      0.00      0.00       0.0\n",
            "       18068       0.00      0.00      0.00       0.0\n",
            "       18069       0.00      0.00      0.00       0.0\n",
            "       18070       0.00      0.00      0.00       0.0\n",
            "       18071       0.00      0.00      0.00       0.0\n",
            "       18072       0.00      0.00      0.00       0.0\n",
            "       18073       0.00      0.00      0.00       0.0\n",
            "       18074       0.00      0.00      0.00       0.0\n",
            "       18075       0.00      0.00      0.00       0.0\n",
            "       18076       0.00      0.00      0.00       0.0\n",
            "       18077       0.00      0.00      0.00       0.0\n",
            "       18078       0.00      0.00      0.00       0.0\n",
            "       18079       0.00      0.00      0.00       0.0\n",
            "       18080       0.00      0.00      0.00       0.0\n",
            "       18081       0.00      0.00      0.00       0.0\n",
            "       18082       0.00      0.00      0.00       0.0\n",
            "       18083       0.00      0.00      0.00       0.0\n",
            "       18084       0.00      0.00      0.00       0.0\n",
            "       18085       0.00      0.00      0.00       0.0\n",
            "       18086       0.00      0.00      0.00       0.0\n",
            "       18087       0.00      0.00      0.00       0.0\n",
            "       18088       0.00      0.00      0.00       0.0\n",
            "       18089       0.00      0.00      0.00       0.0\n",
            "       18090       0.00      0.00      0.00       0.0\n",
            "       18091       0.00      0.00      0.00       0.0\n",
            "       18092       0.00      0.00      0.00       0.0\n",
            "       18093       0.00      0.00      0.00       0.0\n",
            "       18094       0.00      0.00      0.00       0.0\n",
            "       18095       0.00      0.00      0.00       0.0\n",
            "       18096       0.00      0.00      0.00       0.0\n",
            "       18097       0.00      0.00      0.00       0.0\n",
            "       18098       0.00      0.00      0.00       0.0\n",
            "       18099       0.00      0.00      0.00       0.0\n",
            "       18100       0.00      0.00      0.00       0.0\n",
            "       18101       0.00      0.00      0.00       0.0\n",
            "       18102       0.00      0.00      0.00       0.0\n",
            "       18103       0.00      0.00      0.00       0.0\n",
            "       18104       0.00      0.00      0.00       0.0\n",
            "       18105       0.00      0.00      0.00       0.0\n",
            "       18106       0.00      0.00      0.00       0.0\n",
            "       18107       0.00      0.00      0.00       0.0\n",
            "       18108       0.00      0.00      0.00       0.0\n",
            "       18109       0.00      0.00      0.00       0.0\n",
            "       18110       0.00      0.00      0.00       0.0\n",
            "       18111       0.00      0.00      0.00       0.0\n",
            "       18112       0.00      0.00      0.00       0.0\n",
            "       18113       0.00      0.00      0.00       0.0\n",
            "       18114       0.00      0.00      0.00       0.0\n",
            "       18115       0.00      0.00      0.00       0.0\n",
            "       18116       0.00      0.00      0.00       0.0\n",
            "       18117       0.00      0.00      0.00       0.0\n",
            "       18118       0.00      0.00      0.00       0.0\n",
            "       18119       0.00      0.00      0.00       0.0\n",
            "       18120       0.00      0.00      0.00       0.0\n",
            "       18121       0.00      0.00      0.00       0.0\n",
            "       18122       0.00      0.00      0.00       0.0\n",
            "       18123       0.00      0.00      0.00       0.0\n",
            "       18124       0.00      0.00      0.00       0.0\n",
            "       18125       0.00      0.00      0.00       0.0\n",
            "       18126       0.00      0.00      0.00       0.0\n",
            "       18127       0.00      0.00      0.00       0.0\n",
            "       18128       0.00      0.00      0.00       0.0\n",
            "       18129       0.00      0.00      0.00       0.0\n",
            "       18130       0.00      0.00      0.00       0.0\n",
            "       18131       0.00      0.00      0.00       0.0\n",
            "       18132       0.00      0.00      0.00       0.0\n",
            "       18133       0.00      0.00      0.00       0.0\n",
            "       18134       0.00      0.00      0.00       0.0\n",
            "       18135       0.00      0.00      0.00       0.0\n",
            "       18136       0.00      0.00      0.00       0.0\n",
            "       18137       0.00      0.00      0.00       0.0\n",
            "       18138       0.00      0.00      0.00       0.0\n",
            "       18139       0.00      0.00      0.00       0.0\n",
            "       18140       0.00      0.00      0.00       0.0\n",
            "       18141       0.00      0.00      0.00       0.0\n",
            "       18142       0.00      0.00      0.00       0.0\n",
            "       18143       0.00      0.00      0.00       0.0\n",
            "       18144       0.00      0.00      0.00       0.0\n",
            "       18145       0.00      0.00      0.00       0.0\n",
            "       18146       0.00      0.00      0.00       0.0\n",
            "       18147       0.00      0.00      0.00       0.0\n",
            "       18148       0.00      0.00      0.00       0.0\n",
            "       18149       0.00      0.00      0.00       0.0\n",
            "       18150       0.00      0.00      0.00       0.0\n",
            "       18151       0.00      0.00      0.00       0.0\n",
            "       18152       0.00      0.00      0.00       0.0\n",
            "       18154       0.00      0.00      0.00       0.0\n",
            "       18157       0.00      0.00      0.00       0.0\n",
            "       18158       0.00      0.00      0.00       0.0\n",
            "       18159       0.00      0.00      0.00       0.0\n",
            "       18160       0.00      0.00      0.00       0.0\n",
            "       18162       0.00      0.00      0.00       0.0\n",
            "       18164       0.00      0.00      0.00       0.0\n",
            "       18169       0.00      0.00      0.00       0.0\n",
            "       18173       0.00      0.00      0.00       0.0\n",
            "       18176       0.00      0.00      0.00       0.0\n",
            "\n",
            "    accuracy                           0.00    4502.0\n",
            "   macro avg       0.00      0.00      0.00    4502.0\n",
            "weighted avg       0.00      0.00      0.00    4502.0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# test the model\n",
        "loss, accuracy = ann.evaluate(test_ds)\n",
        "\n",
        "print(\"Loss: \", loss)\n",
        "print(\"Accuracy: \", accuracy)\n",
        "\n",
        "# show the result\n",
        "history_dict = history.history\n",
        "#history_dict.keys()\n",
        "\n",
        "acc = history_dict['binary_accuracy']\n",
        "val_acc = history_dict['val_binary_accuracy']\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "# show loss\n",
        "# \"bo\" is for \"blue dot\"\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "# b is for \"solid blue line\"\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# accuracy\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "DVnH2RYXeViB",
        "outputId": "8679ff7f-c23f-4458-849b-c760b2fc7c06"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "141/141 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-70f63ee39405>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mann\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# test the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mann\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2108\u001b[0m     \"\"\"\n\u001b[1;32m   2109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2110\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2112\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     93\u001b[0m         raise ValueError(\n\u001b[1;32m     94\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[0;32m---> 95\u001b[0;31m                 \u001b[0mtype_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m             )\n\u001b[1;32m     97\u001b[0m         )\n",
            "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous targets"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary\n",
        "# accuracy, f1, recall, precision (from weighted avg)\n",
        "\"\"\"\n",
        " 'accuracy': 0.8713904931141715,\n",
        " 'macro avg': {'precision': 0.8595907862212557,\n",
        "  'recall': 0.8094598698526863,\n",
        "  'f1-score': 0.8310936479637612,\n",
        "  'support': 4502},\n",
        " 'weighted avg': {'precision': 0.869011495668078,\n",
        "  'recall': 0.8713904931141715,\n",
        "  'f1-score': 0.8684701422491293,\n",
        "  'support': 4502}}\n",
        "\"\"\"\n",
        "approaches = ['nbc', 'nbc2', 'svm', 'dt']\n",
        "acc = [results[label]['accuracy'] for label in approaches]\n",
        "f1 = [results[label]['weighted avg']['f1-score'] for label in approaches]\n",
        "recall = [results[label]['weighted avg']['recall'] for label in approaches]\n",
        "prec = [results[label]['weighted avg']['precision'] for label in approaches]\n",
        "\n",
        "plt.plot(approaches, f1, label='F1 Score')\n",
        "plt.plot(approaches, recall, label='Recall')\n",
        "plt.plot(approaches, prec,  label='precision')\n",
        "#plt.plot(approaches, val_acc, 'b', label='F1 Score')\n",
        "plt.title('Results')\n",
        "plt.xlabel('Approach')\n",
        "plt.ylabel('Metrics')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "GdFWBMk8X7Eu",
        "outputId": "d5d76416-6993-4d3b-a756-395c30a2b14a"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References\n",
        "\n",
        "CSV reader example code:\\\n",
        "https://realpython.com/python-csv/\n",
        "\n",
        "https://www.geeksforgeeks.org/removing-stop-words-nltk-python/\n",
        "\n",
        "https://www.geeksforgeeks.org/python-stemming-words-with-nltk/?ref=lbp\n",
        "\n",
        "https://stackoverflow.com/questions/29314033/drop-rows-containing-empty-cells-from-a-pandas-dataframe\n",
        "\n",
        "https://stackoverflow.com/questions/613183/how-do-i-sort-a-dictionary-by-value\n",
        "\n",
        "https://towardsdatascience.com/heres-the-most-efficient-way-to-iterate-through-your-pandas-dataframe-4dad88ac92ee"
      ],
      "metadata": {
        "id": "mt01xYnnkhzr"
      }
    }
  ]
}